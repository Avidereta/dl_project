{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import sklearn\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "#%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Pdf\")\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png', 'pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.2 s, sys: 4.31 s, total: 20.5 s\n",
      "Wall time: 20.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open('data_basic.pkl', 'rb') as f:\n",
    "    _, _, y_train, _, _, y_val, _, _, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.1 s, sys: 5.64 s, total: 27.7 s\n",
      "Wall time: 27.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open('data_rem_road.pkl', 'rb') as f:\n",
    "    _, _, y_train, _, _, y_val, _, _, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with open('data_huge.pkl', 'rb') as f:\n",
    "    _, _, y_train, _, _, y_val, _, _, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 51s, sys: 34.2 s, total: 2min 25s\n",
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open('data_huge_rem_road.pkl', 'rb') as f:\n",
    "    _, _, y_train, _, _, y_val, _, _, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2975, (18432,))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f1_train), f1_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 s, sys: 1.19 s, total: 13.3 s\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open('features_rem_road.pkl', 'rb') as f:\n",
    "    f1_train, f1_val, f1_test, f2_train, f2_val, f2_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 50s, sys: 6.05 s, total: 10min 56s\n",
      "Wall time: 10min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open('features_huge_rem_road.pkl', 'rb') as f:\n",
    "    f1_train, f1_val, f1_test, f2_train, f2_val, f2_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('features_basic.pkl', 'rb') as f:\n",
    "    f1_train, f1_val, f1_test, f2_train, f2_val, f2_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with open('features_huge.pkl', 'rb') as f:\n",
    "    f1_train, f2_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  16.,   49.,   88.,  163.,  109.,  125.,  120.,  113.,  127.,\n",
       "         106.,  132.,  134.,  115.,  195.,  295.,  368.,  252.,  131.,\n",
       "         125.,  212.]),\n",
       " array([  14. ,   19.6,   25.2,   30.8,   36.4,   42. ,   47.6,   53.2,\n",
       "          58.8,   64.4,   70. ,   75.6,   81.2,   86.8,   92.4,   98. ,\n",
       "         103.6,  109.2,  114.8,  120.4,  126. ]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/pdf": "JVBERi0xLjQKJazcIKu6CjEgMCBvYmoKPDwgL1R5cGUgL0NhdGFsb2cgL1BhZ2VzIDIgMCBSID4+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\nRU9GCg==\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEACAYAAABS29YJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntYBhL0ktYNhLUgv8fyho3QYo5crbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x36185ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2975, array([86, 93, 43, ..., 39, 97, 95], dtype=uint8))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train), y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = [np.percentile(y_train, 0),\n",
    "        np.percentile(y_train, 25),\n",
    "        np.percentile(y_train, 50),\n",
    "        np.percentile(y_train, 75),\n",
    "        np.percentile(y_train, 100) + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14.0, 57.0, 89.0, 103.0, 127.0]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_bins = [np.percentile(y_train, 0),\n",
    "               np.percentile(y_train, 50),\n",
    "               np.percentile(y_train, 100) + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14.0, 89.0, 127.0]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_binary = np.digitize(y_train, binary_bins) - 1\n",
    "y_val_binary = np.digitize(y_val, binary_bins) - 1\n",
    "y_test_binary = np.digitize(y_test, binary_bins) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = np.digitize(y_train, bins) - 1\n",
    "y_val = np.digitize(y_val, bins) - 1\n",
    "y_test = np.digitize(y_test, bins) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 739.,    0.,    0.,  715.,    0.,    0.,  721.,    0.,    0.,  800.]),\n",
       " array([ 0. ,  0.3,  0.6,  0.9,  1.2,  1.5,  1.8,  2.1,  2.4,  2.7,  3. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/pdf": "JVBERi0xLjQKJazcIKu6CjEgMCBvYmoKPDwgL1R5cGUgL0NhdGFsb2cgL1BhZ2VzIDIgMCBSID4+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\nZWYKNjIzNQolJUVPRgo=\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOINekhpn0EtS4wx6SWqcQS9Jjft/w46WgDiY51wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x55cacc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1454.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,  1521.]),\n",
       " array([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/pdf": "JVBERi0xLjQKJazcIKu6CjEgMCBvYmoKPDwgL1R5cGUgL0NhdGFsb2cgL1BhZ2VzIDIgMCBSID4+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\nNTI2NgolJUVPRgo=\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEACAYAAABbMHZzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyeCc3XIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd62bd10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.878"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.01, penalty='l1')\n",
    "clf.fit(f1_train, y_train_binary).score(f1_val, y_val_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without the road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68000000000000005"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.01, penalty='l1')\n",
    "clf.fit(f1_train, y_train).score(f1_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "normalizer = Normalizer().fit(f1_train)\n",
    "f1_train_normalized = normalizer.transform(f1_train)\n",
    "f1_val_normalized = normalizer.transform(f1_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67000000000000004"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC(C=1, penalty='l2', loss='squared_hinge', dual=True, multi_class='crammer_singer')\n",
    "clf.fit(f1_train_normalized, y_train).score(f1_val_normalized, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67000000000000004"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=8, penalty='l1')\n",
    "clf.fit(f1_train_normalized, y_train).score(f1_val_normalized, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66800000000000004"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(C=1, kernel='rbf', gamma=1)\n",
    "clf.fit(f1_train_normalized, y_train).score(f1_val_normalized, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67400000000000004"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(C=1, kernel='poly', gamma=1, degree=2)\n",
    "clf.fit(f1_train_normalized, y_train).score(f1_val_normalized, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=1000).fit(f1_train_normalized)\n",
    "\n",
    "f1_train_pca = pca.transform(f1_train_normalized)\n",
    "f1_val_pca = pca.transform(f1_val_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59799999999999998"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "GradientBoostingClassifier(n_estimators=200).fit(f1_train_pca, y_train).score(f1_val_pca, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python2.7/site-packages/sklearn/cross_validation.py:69: DeprecationWarning: The indices parameter is deprecated and will be removed (assumed True) in 0.17\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Stacking(base_estimators=[(<bound method LogisticRegression.fit of LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0)>, <f...on <lambda> at 0x1d848848>), (<function <lambda> at 0x1d848758>, <function <lambda> at 0x1d8488c0>)],\n",
       "     extend_meta=False, meta_fitter=None, n_folds=5)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stacking import Stacking\n",
    "\n",
    "basic_wildfowl = Stacking(base_estimators=[\n",
    "        (LogisticRegression(C=0.01, penalty='l1').fit,\n",
    "         lambda clf, X: clf.predict(X)),\n",
    "        (lambda X, y: LinearSVC(C=1, penalty='l2', loss='squared_hinge',\n",
    "                                dual=True, multi_class='crammer_singer').fit(normalizer.transform(X), y),\n",
    "         lambda clf, X: clf.predict(normalizer.transform(X))),\n",
    "        (lambda X, y: LogisticRegression(C=8, penalty='l1').fit(normalizer.transform(X), y),\n",
    "         lambda clf, X: clf.predict(normalizer.transform(X))),\n",
    "        (lambda X, y: SVC(C=1, kernel='rbf', gamma=1).fit(normalizer.transform(X), y),\n",
    "         lambda clf, X: clf.predict(normalizer.transform(X))),\n",
    "        (lambda X, y: SVC(C=1, kernel='poly', gamma=1, degree=2).fit(normalizer.transform(X), y),\n",
    "         lambda clf, X: clf.predict(normalizer.transform(X)))],\n",
    "                    n_folds=5, extend_meta=False)\n",
    "basic_wildfowl.fit(np.array(f1_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68999999999999995"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_wildfowl.fit_meta(SVC(C=5, kernel='poly', degree=2, gamma=1.).fit).score(np.array(f1_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68999999999999995"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_wildfowl.fit_meta(SVC(C=1, kernel='poly', degree=2, gamma=1.).fit).score(np.array(f1_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68999999999999995"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_wildfowl.fit_meta(SVC(C=10, kernel='poly', degree=2, gamma=1.).fit).score(np.array(f1_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69799999999999995"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_wildfowl.fit_meta(SVC(C=1, kernel='rbf', gamma=1.).fit).score(np.array(f1_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70399999999999996"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_wildfowl.fit_meta(SVC(C=1, kernel='rbf', gamma=0.5).fit).score(np.array(f1_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70199999999999996"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_wildfowl.fit_meta(SVC(C=1, kernel='rbf', gamma=0.3).fit).score(np.array(f1_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70599999999999996"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_wildfowl.fit_meta(SVC(C=1, kernel='rbf', gamma=0.2).fit).score(np.array(f1_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70399999999999996"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_wildfowl.fit_meta(SVC(C=1, kernel='rbf', gamma=0.1).fit).score(np.array(f1_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69599999999999995"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_wildfowl.fit_meta(SVC(C=5, kernel='rbf', gamma=1.).fit).score(np.array(f1_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69399999999999995"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_wildfowl.fit_meta(SVC(C=0.5, kernel='rbf', gamma=1.).fit).score(np.array(f1_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67000000000000004"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_wildfowl.fit_meta(LogisticRegression(C=1, penalty='l1').fit).score(np.array(f1_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67000000000000004"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_wildfowl.fit_meta(LogisticRegression(C=10, penalty='l2').fit).score(np.array(f1_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69599999999999995"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_wildfowl.fit_meta(RandomForestClassifier(n_estimators=100).fit).score(np.array(f1_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68999999999999995"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_wildfowl.fit_meta(RandomForestClassifier(n_estimators=50, max_depth=10).fit).score(np.array(f1_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69599999999999995"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_wildfowl.fit_meta(RandomForestClassifier(n_estimators=50, max_depth=20).fit).score(np.array(f1_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69399999999999995"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_wildfowl.fit_meta(GradientBoostingClassifier(n_estimators=200).fit).score(np.array(f1_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67000000000000004"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_wildfowl.fit_meta(AdaBoostClassifier(n_estimators=30).fit).score(np.array(f1_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68799999999999994"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_wildfowl.fit_meta(AdaBoostClassifier(n_estimators=50).fit).score(np.array(f1_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68000000000000005"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_wildfowl.fit_meta(AdaBoostClassifier(n_estimators=100).fit).score(np.array(f1_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88369747899159667"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_wildfowl.score(np.array(f1_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python2.7/site-packages/sklearn/cross_validation.py:69: DeprecationWarning: The indices parameter is deprecated and will be removed (assumed True) in 0.17\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Stacking(base_estimators=[(<bound method LogisticRegression.fit of LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0)>, <f...on <lambda> at 0x3a2548c0>), (<function <lambda> at 0x2ae631b8>, <function <lambda> at 0x2ae635f0>)],\n",
       "     extend_meta=False, meta_fitter=None, n_folds=5)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stacking import Stacking\n",
    "\n",
    "binary_wildfowl = Stacking(base_estimators=[\n",
    "        (LogisticRegression(C=0.01, penalty='l1').fit,\n",
    "         lambda clf, X: clf.predict(X)),\n",
    "        (lambda X, y: LinearSVC(C=1, penalty='l2', loss='squared_hinge',\n",
    "                                dual=True, multi_class='crammer_singer').fit(normalizer.transform(X), y),\n",
    "         lambda clf, X: clf.predict(normalizer.transform(X))),\n",
    "        (lambda X, y: LogisticRegression(C=8, penalty='l1').fit(normalizer.transform(X), y),\n",
    "         lambda clf, X: clf.predict(normalizer.transform(X))),\n",
    "        (lambda X, y: SVC(C=1, kernel='rbf', gamma=1).fit(normalizer.transform(X), y),\n",
    "         lambda clf, X: clf.predict(normalizer.transform(X))),\n",
    "        (lambda X, y: SVC(C=1, kernel='poly', gamma=1, degree=2).fit(normalizer.transform(X), y),\n",
    "         lambda clf, X: clf.predict(normalizer.transform(X)))],\n",
    "                    n_folds=5, extend_meta=False)\n",
    "binary_wildfowl.fit(np.array(f1_train), y_train_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88400000000000001"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_wildfowl.fit_meta(LogisticRegression().fit).score(np.array(f1_val), y_val_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With the road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68000000000000005"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.01, penalty='l1')\n",
    "clf.fit(f1_train, y_train).score(f1_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67800000000000005"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.1, penalty='l1')\n",
    "clf.fit(np.hstack((f1_train, f2_train)), y_train).score(np.hstack((f1_val, f2_val)), y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18432,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "normalizer = Normalizer().fit(f1_train)\n",
    "f1_train_normalized = normalizer.transform(f1_train)\n",
    "f1_val_normalized = normalizer.transform(f1_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=300).fit(f1_train_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1_train_pca = pca.transform(f1_train_normalized)\n",
    "f1_val_pca = pca.transform(f1_val_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59799999999999998"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "GradientBoostingClassifier(n_estimators=200).fit(f1_train_pca, y_train).score(f1_val_pca, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With the road + segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67600000000000005"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.005, penalty='l1')\n",
    "clf.fit(np.hstack((np.array(f1_train), np.array(f2_train))), y_train).score(np.hstack((np.array(f1_val), np.array(f2_val))), y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Road deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68000000000000005"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.01, penalty='l1')\n",
    "clf.fit(np.array(f1_train), y_train).score(np.array(f1_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(np.array(f1_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[137,  10,   0,   2],\n",
       "       [ 29,  78,  15,   6],\n",
       "       [  8,  13,  40,  32],\n",
       "       [  9,   9,  27,  85]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 2, 0, 0, 2, 0, 0, 0, 0, 3, 3, 0, 3,\n",
       "       2, 3, 0, 3, 0, 2, 2, 3, 1, 1, 3, 2, 0, 0, 3, 3, 2, 0, 0, 0, 1, 1, 0,\n",
       "       3, 0, 0, 1, 1, 0, 1, 3, 0, 0, 0, 0, 0, 3, 0, 2, 3, 3, 1, 0, 3, 0, 0,\n",
       "       0, 0, 0, 0, 0, 3, 0, 1, 1, 3, 3, 3, 1, 1, 3, 2, 3, 3, 0, 3, 1, 3, 3,\n",
       "       3, 0, 0, 3, 2, 3, 2, 1, 3, 1, 3, 2, 0, 0, 0, 3, 3, 0, 2, 0, 3, 3, 0,\n",
       "       1, 1, 1, 3, 0, 3, 0, 0, 0, 3, 3, 3, 0, 3, 0, 0, 1, 0, 0, 0, 1, 1, 3,\n",
       "       3, 0, 3, 0, 0, 1, 3, 0, 3, 0, 3, 3, 0, 3, 3, 1, 3, 0, 0, 3, 3, 0, 0,\n",
       "       0, 0, 3, 0, 1, 1, 1, 0, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0,\n",
       "       0, 2, 0, 1, 0, 0, 0, 3, 1, 3, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 3, 1,\n",
       "       1, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 2, 3, 0, 1, 1, 1, 1, 0, 1, 3, 0,\n",
       "       0, 0, 3, 1, 0, 0, 1, 0, 3, 3, 3, 0, 3, 3, 0, 3, 3, 0, 0, 1, 0, 0, 3,\n",
       "       1, 0, 1, 2, 2, 1, 3, 1, 3, 3, 3, 0, 0, 2, 1, 2, 1, 0, 0, 0, 0, 2, 1,\n",
       "       1, 1, 2, 2, 2, 2, 0, 0, 2, 3, 3, 2, 2, 3, 2, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       2, 0, 2, 3, 0, 1, 1, 0, 3, 0, 1, 0, 3, 3, 2, 3, 3, 2, 3, 3, 2, 1, 3,\n",
       "       2, 2, 1, 1, 1, 0, 2, 0, 0, 1, 2, 2, 3, 3, 1, 1, 1, 0, 0, 1, 2, 3, 2,\n",
       "       2, 1, 1, 0, 2, 0, 0, 3, 1, 0, 2, 1, 3, 0, 0, 1, 3, 3, 0, 0, 0, 3, 0,\n",
       "       2, 3, 0, 1, 2, 2, 2, 0, 0, 0, 2, 2, 1, 1, 3, 2, 2, 3, 2, 1, 2, 2, 2,\n",
       "       1, 0, 2, 0, 1, 3, 0, 1, 1, 2, 1, 2, 0, 1, 2, 2, 3, 3, 1, 2, 1, 2, 1,\n",
       "       2, 0, 0, 0, 2, 1, 0, 3, 2, 1, 3, 3, 0, 1, 0, 0, 1, 0, 2, 2, 1, 0, 2,\n",
       "       1, 2, 0, 3, 0, 3, 1, 0, 2, 1, 0, 2, 1, 1, 3, 0, 3, 0, 0, 2, 3, 1, 3,\n",
       "       0, 0, 0, 1, 0, 2, 1, 1, 2, 3, 1, 0, 0, 1, 3, 2, 3, 1, 3, 1, 2, 0, 0,\n",
       "       1, 1, 2, 2, 3, 0, 3, 2, 1, 0, 2, 0, 0, 0, 1, 3, 2])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = np.array(f1_train).shape[1]\n",
    "k = n / 3\n",
    "P = np.random.randn(n, k) / np.sqrt(k)\n",
    "\n",
    "f1_train_p = np.array(f1_train).dot(P)\n",
    "f1_val_p = np.array(f1_val).dot(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66000000000000003"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.01, penalty='l1')\n",
    "clf.fit(f1_train_p, y_train).score(f1_val_p, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "normalizer = Normalizer().fit(f1_train)\n",
    "f1_train_normalized = normalizer.transform(f1_train)\n",
    "f1_val_normalized = normalizer.transform(f1_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67000000000000004"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=15, penalty='l2')\n",
    "clf.fit(f1_train_normalized, y_train).score(f1_val_normalized, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67000000000000004"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stacking import Stacking, Classifier\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "def logit_proba_fitter(X, y):\n",
    "    classifier = LogisticRegression(C=15, penalty='l2').fit(X, y)\n",
    "    return Classifier(classifier.predict_proba)\n",
    "\n",
    "def logit_fitter(X, y):\n",
    "    classifier = LinearSVC(C=0.5).fit(X, y)\n",
    "    return Classifier(classifier.predict)\n",
    "\n",
    "logit_logit = Stacking(base_fitter=logit_proba_fitter, meta_fitter=logit_fitter,\n",
    "                       split=lambda I: list(KFold(n=I.size, n_folds=10, shuffle=True)))\n",
    "logit_logit.fit(f1_train_normalized, y_train).score(f1_val_normalized, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67600000000000005"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC(C=0.5)\n",
    "clf.fit(f1_train_normalized, y_train).score(f1_val_normalized, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road deleted + segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66600000000000004"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.001, penalty='l1')\n",
    "clf.fit(np.hstack((np.array(f1_train), np.array(f2_train))), y_train).score(np.hstack((np.array(f1_val), np.array(f2_val))), y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    2.,    16.,   207.,   755.,  1324.,  1458.,  1633.,  1312.,\n",
       "         1345.,  1370.,  1734.,  1487.,  1421.,  1543.,  1626.,  1843.,\n",
       "         1958.,   818.,   455.,   665.]),\n",
       " array([   0. ,    6.3,   12.6,   18.9,   25.2,   31.5,   37.8,   44.1,\n",
       "          50.4,   56.7,   63. ,   69.3,   75.6,   81.9,   88.2,   94.5,\n",
       "         100.8,  107.1,  113.4,  119.7,  126. ]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/pdf": "JVBERi0xLjQKJazcIKu6CjEgMCBvYmoKPDwgL1R5cGUgL0NhdGFsb2cgL1BhZ2VzIDIgMCBSID4+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\nJSVFT0YK\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkhpmCEhSw/4fbKxnjTewLy8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x55ce6250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins_extra = [np.percentile(y_train, 0),\n",
    "        np.percentile(y_train, 25),\n",
    "        np.percentile(y_train, 50),\n",
    "        np.percentile(y_train, 75),\n",
    "        np.percentile(y_train, 100) + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 46.0, 71.0, 94.0, 127.0]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.digitize(y_train, bins_extra) - 1\n",
    "y_val = np.digitize(y_val, bins_extra) - 1\n",
    "y_test = np.digitize(y_test, bins_extra) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5612.,     0.,     0.,  5779.,     0.,     0.,  5556.,     0.,\n",
       "            0.,  6025.]),\n",
       " array([ 0. ,  0.3,  0.6,  0.9,  1.2,  1.5,  1.8,  2.1,  2.4,  2.7,  3. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/pdf": "JVBERi0xLjQKJazcIKu6CjEgMCBvYmoKPDwgL1R5cGUgL0NhdGFsb2cgL1BhZ2VzIDIgMCBSID4+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\nNiA+PgpzdGFydHhyZWYKNTgxMQolJUVPRgo=\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEACAYAAAC6d6FnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28599f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70199999999999996"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.01, penalty='l1')\n",
    "clf.fit(f1_train, y_train).score(f1_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basic_wildfowl = Stacking(base_estimators=[\n",
    "        (LogisticRegression(C=0.01, penalty='l1').fit,\n",
    "         lambda clf, X: clf.predict(X)),\n",
    "        (lambda X, y: LinearSVC(C=1, penalty='l2', loss='squared_hinge',\n",
    "                                dual=True, multi_class='crammer_singer').fit(normalizer.transform(X), y),\n",
    "         lambda clf, X: clf.predict(normalizer.transform(X))),\n",
    "        (lambda X, y: LogisticRegression(C=8, penalty='l1').fit(normalizer.transform(X), y),\n",
    "         lambda clf, X: clf.predict(normalizer.transform(X))),\n",
    "        (lambda X, y: SVC(C=1, kernel='rbf', gamma=1).fit(normalizer.transform(X), y),\n",
    "         lambda clf, X: clf.predict(normalizer.transform(X))),\n",
    "        (lambda X, y: SVC(C=1, kernel='poly', gamma=1, degree=2).fit(normalizer.transform(X), y),\n",
    "         lambda clf, X: clf.predict(normalizer.transform(X)))],\n",
    "                    n_folds=5, extend_meta=False)\n",
    "basic_wildfowl.fit(np.array(f1_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basic_wildfowl.fit_meta(SVC(C=1, kernel='rbf', gamma=0.2).fit).score(np.array(f1_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network deleted road, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W, b, W, b, W, b, W, b, W, b, W, b]\n",
      "Epoch 1 of 30 took 1.998s\n",
      "  training loss (in-iteration):\t\t3749.619600\n",
      "  train accuracy:\t\t28.59 %\n",
      "  validation accuracy:\t\t26.00 %\n",
      "Epoch 2 of 30 took 2.015s\n",
      "  training loss (in-iteration):\t\t3.113019\n",
      "  train accuracy:\t\t32.24 %\n",
      "  validation accuracy:\t\t46.60 %\n",
      "Epoch 3 of 30 took 1.982s\n",
      "  training loss (in-iteration):\t\t2.176733\n",
      "  train accuracy:\t\t45.90 %\n",
      "  validation accuracy:\t\t49.40 %\n",
      "Epoch 4 of 30 took 2.010s\n",
      "  training loss (in-iteration):\t\t1.896570\n",
      "  train accuracy:\t\t52.72 %\n",
      "  validation accuracy:\t\t58.00 %\n",
      "Epoch 5 of 30 took 1.978s\n",
      "  training loss (in-iteration):\t\t1.765641\n",
      "  train accuracy:\t\t58.38 %\n",
      "  validation accuracy:\t\t52.20 %\n",
      "Epoch 6 of 30 took 2.000s\n",
      "  training loss (in-iteration):\t\t1.671071\n",
      "  train accuracy:\t\t63.17 %\n",
      "  validation accuracy:\t\t62.00 %\n",
      "Epoch 7 of 30 took 2.000s\n",
      "  training loss (in-iteration):\t\t1.551463\n",
      "  train accuracy:\t\t69.31 %\n",
      "  validation accuracy:\t\t55.20 %\n",
      "Epoch 8 of 30 took 2.111s\n",
      "  training loss (in-iteration):\t\t1.477413\n",
      "  train accuracy:\t\t71.52 %\n",
      "  validation accuracy:\t\t66.60 %\n",
      "Epoch 9 of 30 took 2.005s\n",
      "  training loss (in-iteration):\t\t1.404215\n",
      "  train accuracy:\t\t76.62 %\n",
      "  validation accuracy:\t\t59.40 %\n",
      "Epoch 10 of 30 took 1.980s\n",
      "  training loss (in-iteration):\t\t1.373313\n",
      "  train accuracy:\t\t76.55 %\n",
      "  validation accuracy:\t\t67.40 %\n",
      "Epoch 11 of 30 took 1.987s\n",
      "  training loss (in-iteration):\t\t1.343516\n",
      "  train accuracy:\t\t77.24 %\n",
      "  validation accuracy:\t\t60.80 %\n",
      "Epoch 12 of 30 took 2.008s\n",
      "  training loss (in-iteration):\t\t1.256678\n",
      "  train accuracy:\t\t81.34 %\n",
      "  validation accuracy:\t\t61.20 %\n",
      "Epoch 13 of 30 took 2.102s\n",
      "  training loss (in-iteration):\t\t1.214769\n",
      "  train accuracy:\t\t83.93 %\n",
      "  validation accuracy:\t\t66.20 %\n",
      "Epoch 14 of 30 took 1.999s\n",
      "  training loss (in-iteration):\t\t1.203365\n",
      "  train accuracy:\t\t84.66 %\n",
      "  validation accuracy:\t\t61.60 %\n",
      "Epoch 15 of 30 took 1.974s\n",
      "  training loss (in-iteration):\t\t1.129455\n",
      "  train accuracy:\t\t87.41 %\n",
      "  validation accuracy:\t\t67.00 %\n",
      "Epoch 16 of 30 took 2.126s\n",
      "  training loss (in-iteration):\t\t1.263559\n",
      "  train accuracy:\t\t85.00 %\n",
      "  validation accuracy:\t\t67.40 %\n",
      "Epoch 17 of 30 took 1.980s\n",
      "  training loss (in-iteration):\t\t1.062010\n",
      "  train accuracy:\t\t91.52 %\n",
      "  validation accuracy:\t\t65.40 %\n",
      "Epoch 18 of 30 took 1.974s\n",
      "  training loss (in-iteration):\t\t1.000695\n",
      "  train accuracy:\t\t93.72 %\n",
      "  validation accuracy:\t\t64.40 %\n",
      "Epoch 19 of 30 took 2.005s\n",
      "  training loss (in-iteration):\t\t0.974304\n",
      "  train accuracy:\t\t94.59 %\n",
      "  validation accuracy:\t\t64.00 %\n",
      "Epoch 20 of 30 took 1.980s\n",
      "  training loss (in-iteration):\t\t0.925185\n",
      "  train accuracy:\t\t96.62 %\n",
      "  validation accuracy:\t\t62.00 %\n",
      "Epoch 21 of 30 took 2.003s\n",
      "  training loss (in-iteration):\t\t0.937583\n",
      "  train accuracy:\t\t96.28 %\n",
      "  validation accuracy:\t\t62.60 %\n",
      "Epoch 22 of 30 took 1.997s\n",
      "  training loss (in-iteration):\t\t1.025416\n",
      "  train accuracy:\t\t93.21 %\n",
      "  validation accuracy:\t\t62.00 %\n",
      "Epoch 23 of 30 took 1.987s\n",
      "  training loss (in-iteration):\t\t1.056850\n",
      "  train accuracy:\t\t92.55 %\n",
      "  validation accuracy:\t\t63.80 %\n",
      "Epoch 24 of 30 took 1.997s\n",
      "  training loss (in-iteration):\t\t0.880320\n",
      "  train accuracy:\t\t98.07 %\n",
      "  validation accuracy:\t\t64.40 %\n",
      "Epoch 25 of 30 took 2.182s\n",
      "  training loss (in-iteration):\t\t0.861131\n",
      "  train accuracy:\t\t98.76 %\n",
      "  validation accuracy:\t\t64.80 %\n",
      "Epoch 26 of 30 took 2.169s\n",
      "  training loss (in-iteration):\t\t0.866686\n",
      "  train accuracy:\t\t98.07 %\n",
      "  validation accuracy:\t\t64.60 %\n",
      "Epoch 27 of 30 took 2.097s\n",
      "  training loss (in-iteration):\t\t0.839886\n",
      "  train accuracy:\t\t99.03 %\n",
      "  validation accuracy:\t\t64.80 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-d82e6a4058e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mtrain_err_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0mtrain_err\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain_err_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain_acc_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    813\u001b[0m                         s.storage[0] = s.type.filter(\n\u001b[0;32m    814\u001b[0m                             \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 815\u001b[1;33m                             allow_downcast=s.allow_downcast)\n\u001b[0m\u001b[0;32m    816\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/tensor/type.pyc\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, data, strict, allow_downcast)\u001b[0m\n\u001b[0;32m    148\u001b[0m                     \u001b[1;31m# data has to be converted.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m                     \u001b[1;31m# Check that this conversion is lossless\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m                     \u001b[0mconverted_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_asarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m                     \u001b[1;31m# We use the `values_eq` static function from TensorType\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m                     \u001b[1;31m# to handle NaN values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/misc/safe_asarray.pyc\u001b[0m in \u001b[0;36m_asarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Convert into dtype object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[1;31m# Note that dtype comparison must be done by comparing their `num`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# attribute. One cannot assume that two identical data types are pointers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib64/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \"\"\"\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open('data_rem_road.pkl', 'rb') as f:\n",
    "    X_train, Seg_train, y_train, X_val, Seg_val, y_val, X_test, Seg_test, y_test = pickle.load(f)\n",
    "    \n",
    "with open('features_rem_road.pkl', 'rb') as f:\n",
    "    f1_train, f1_val, f1_test, f2_train, f2_val, f2_test = pickle.load(f)\n",
    "    \n",
    "bins = [np.percentile(y_train, 0),\n",
    "        np.percentile(y_train, 25),\n",
    "        np.percentile(y_train, 50),\n",
    "        np.percentile(y_train, 75),\n",
    "        np.percentile(y_train, 100) + 1]\n",
    "\n",
    "y_train = np.digitize(y_train, bins) - 1\n",
    "y_val = np.digitize(y_val, bins) - 1\n",
    "y_test = np.digitize(y_test, bins) - 1\n",
    "\n",
    "input_layer = InputLayer((None, f1_train[0].shape[0]))\n",
    "ll1 = DenseLayer(input_layer, num_units=2048, nonlinearity=lasagne.nonlinearities.elu)\n",
    "dr1 = DropoutLayer(ll1, p=0.5)\n",
    "ll2 = DenseLayer(dr1, num_units=2048, nonlinearity=lasagne.nonlinearities.elu)\n",
    "dr3 = DropoutLayer(ll2, p=0.5)\n",
    "ll3 = DenseLayer(dr3, num_units=1024, nonlinearity=lasagne.nonlinearities.elu)\n",
    "dr4 = DropoutLayer(ll3, p=0.5)\n",
    "ll4 = DenseLayer(dr4, num_units=512, nonlinearity=lasagne.nonlinearities.elu)\n",
    "dr5 = DropoutLayer(ll4, p=0.5)\n",
    "ll5 = DenseLayer(dr5, num_units=256, nonlinearity=lasagne.nonlinearities.elu)\n",
    "dr6 = DropoutLayer(ll5, p=0.5)\n",
    "percentile = DenseLayer(dr6, num_units=len(set(y_train)), nonlinearity=softmax)\n",
    "\n",
    "target_y = T.vector(\"target Y integer\", dtype='int32')\n",
    "input_X = T.matrix('X')\n",
    "\n",
    "probs = lasagne.layers.get_output(percentile, input_X, deterministic = True)\n",
    "y_predicted = np.argmax(probs, axis=1)\n",
    "\n",
    "#all network weights (shared variables)\n",
    "all_weights = lasagne.layers.get_all_params(percentile)\n",
    "print(all_weights)\n",
    "\n",
    "#Mean categorical crossentropy as a loss function - similar to logistic loss but for multiclass targets\n",
    "loss = lasagne.objectives.categorical_crossentropy(probs, target_y).mean()\n",
    "l2_penalty = regularize_layer_params(percentile, l2) * 1e-1\n",
    "l1_penalty = regularize_layer_params(percentile, l1) * 1e-3\n",
    "loss += l2_penalty + l1_penalty\n",
    "\n",
    "#prediction accuracy\n",
    "accuracy = lasagne.objectives.categorical_accuracy(probs, target_y).mean()\n",
    "\n",
    "#This function computes gradient AND composes weight updates just like you did earlier\n",
    "updates_sgd = lasagne.updates.adagrad(loss, all_weights, learning_rate=0.01)\n",
    "\n",
    "#function that computes loss and updates weights\n",
    "train_fun = theano.function([input_X, target_y], [loss, accuracy], updates = updates_sgd)\n",
    "\n",
    "#function that just computes accuracy\n",
    "accuracy_fun = theano.function([input_X, target_y],accuracy)\n",
    "\n",
    "num_epochs = 30 #amount of passes through the data\n",
    "\n",
    "batch_size = 100 #number of samples processed at each function call\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(f1_train, y_train, batch_size):\n",
    "        inputs, targets = batch\n",
    "        train_err_batch, train_acc_batch = train_fun(inputs, targets.astype(np.int32))\n",
    "        train_err += train_err_batch\n",
    "        train_acc += train_acc_batch\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(f1_val, y_val, batch_size):\n",
    "        inputs, targets = batch\n",
    "        val_acc += accuracy_fun(inputs, targets.astype(np.int32))\n",
    "        val_batches += 1\n",
    "\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "\n",
    "    print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  train accuracy:\\t\\t{:.2f} %\".format(\n",
    "        train_acc / train_batches * 100))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network with road, 5 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data_basic.pkl', 'rb') as f:\n",
    "    X_train, Seg_train, y_train, X_val, Seg_val, y_val, X_test, Seg_test, y_test = pickle.load(f)\n",
    "    \n",
    "with open('features_basic.pkl', 'rb') as f:\n",
    "    f1_train, f1_val, f1_test, f2_train, f2_val, f2_test = pickle.load(f)\n",
    "    \n",
    "bins = [np.percentile(y_train, 0),\n",
    "        np.percentile(y_train, 25),\n",
    "        np.percentile(y_train, 50),\n",
    "        np.percentile(y_train, 75),\n",
    "        np.percentile(y_train, 100) + 1]\n",
    "\n",
    "y_train = np.digitize(y_train, bins) - 1\n",
    "y_val = np.digitize(y_val, bins) - 1\n",
    "y_test = np.digitize(y_test, bins) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W, b, W, b, W, b, W, b, W, b, W, b]\n",
      "Epoch 1 of 300 took 2.036s\n",
      "  training loss (in-iteration):\t\t140.387504\n",
      "  train accuracy:\t\t31.28 %\n",
      "  validation accuracy:\t\t52.80 %\n",
      "Epoch 2 of 300 took 2.016s\n",
      "  training loss (in-iteration):\t\t13.295092\n",
      "  train accuracy:\t\t55.17 %\n",
      "  validation accuracy:\t\t58.20 %\n",
      "Epoch 3 of 300 took 2.002s\n",
      "  training loss (in-iteration):\t\t12.705572\n",
      "  train accuracy:\t\t62.45 %\n",
      "  validation accuracy:\t\t60.40 %\n",
      "Epoch 4 of 300 took 2.003s\n",
      "  training loss (in-iteration):\t\t12.226186\n",
      "  train accuracy:\t\t68.86 %\n",
      "  validation accuracy:\t\t60.40 %\n",
      "Epoch 5 of 300 took 2.002s\n",
      "  training loss (in-iteration):\t\t11.880651\n",
      "  train accuracy:\t\t71.07 %\n",
      "  validation accuracy:\t\t60.20 %\n",
      "Epoch 6 of 300 took 2.014s\n",
      "  training loss (in-iteration):\t\t11.404465\n",
      "  train accuracy:\t\t79.07 %\n",
      "  validation accuracy:\t\t61.80 %\n",
      "Epoch 7 of 300 took 2.018s\n",
      "  training loss (in-iteration):\t\t11.053822\n",
      "  train accuracy:\t\t84.86 %\n",
      "  validation accuracy:\t\t65.00 %\n",
      "Epoch 8 of 300 took 1.896s\n",
      "  training loss (in-iteration):\t\t10.977491\n",
      "  train accuracy:\t\t79.59 %\n",
      "  validation accuracy:\t\t61.00 %\n",
      "Epoch 9 of 300 took 2.035s\n",
      "  training loss (in-iteration):\t\t10.554585\n",
      "  train accuracy:\t\t87.14 %\n",
      "  validation accuracy:\t\t65.00 %\n",
      "Epoch 10 of 300 took 1.963s\n",
      "  training loss (in-iteration):\t\t10.316450\n",
      "  train accuracy:\t\t90.83 %\n",
      "  validation accuracy:\t\t64.80 %\n",
      "Epoch 11 of 300 took 1.936s\n",
      "  training loss (in-iteration):\t\t10.013761\n",
      "  train accuracy:\t\t95.55 %\n",
      "  validation accuracy:\t\t63.40 %\n",
      "Epoch 12 of 300 took 1.933s\n",
      "  training loss (in-iteration):\t\t9.810423\n",
      "  train accuracy:\t\t97.24 %\n",
      "  validation accuracy:\t\t63.80 %\n",
      "Epoch 13 of 300 took 1.933s\n",
      "  training loss (in-iteration):\t\t9.722251\n",
      "  train accuracy:\t\t95.52 %\n",
      "  validation accuracy:\t\t63.00 %\n",
      "Epoch 14 of 300 took 1.922s\n",
      "  training loss (in-iteration):\t\t9.467655\n",
      "  train accuracy:\t\t99.24 %\n",
      "  validation accuracy:\t\t64.40 %\n",
      "Epoch 15 of 300 took 1.951s\n",
      "  training loss (in-iteration):\t\t9.321485\n",
      "  train accuracy:\t\t99.38 %\n",
      "  validation accuracy:\t\t66.20 %\n",
      "Epoch 16 of 300 took 1.924s\n",
      "  training loss (in-iteration):\t\t9.184269\n",
      "  train accuracy:\t\t99.72 %\n",
      "  validation accuracy:\t\t65.60 %\n",
      "Epoch 17 of 300 took 1.955s\n",
      "  training loss (in-iteration):\t\t9.060074\n",
      "  train accuracy:\t\t99.86 %\n",
      "  validation accuracy:\t\t65.60 %\n",
      "Epoch 18 of 300 took 2.053s\n",
      "  training loss (in-iteration):\t\t8.943007\n",
      "  train accuracy:\t\t99.93 %\n",
      "  validation accuracy:\t\t64.40 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-c68afadbdafd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mtrain_err_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mtrain_err\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain_err_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain_acc_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_layer = InputLayer((None, f1_train[0].shape[0]))\n",
    "ll1 = DenseLayer(input_layer, num_units=2048, nonlinearity=lasagne.nonlinearities.elu)\n",
    "dr1 = DropoutLayer(ll1, p=0.5)\n",
    "ll2 = DenseLayer(dr1, num_units=2048, nonlinearity=lasagne.nonlinearities.elu)\n",
    "dr3 = DropoutLayer(ll2, p=0.5)\n",
    "ll3 = DenseLayer(dr3, num_units=1024, nonlinearity=lasagne.nonlinearities.elu)\n",
    "dr4 = DropoutLayer(ll3, p=0.5)\n",
    "ll4 = DenseLayer(dr4, num_units=512, nonlinearity=lasagne.nonlinearities.elu)\n",
    "dr5 = DropoutLayer(ll4, p=0.5)\n",
    "ll5 = DenseLayer(dr5, num_units=256, nonlinearity=lasagne.nonlinearities.elu)\n",
    "dr6 = DropoutLayer(ll5, p=0.5)\n",
    "percentile = DenseLayer(dr6, num_units=len(set(y_train)), nonlinearity=softmax)\n",
    "\n",
    "target_y = T.vector(\"target Y integer\", dtype='int32')\n",
    "input_X = T.matrix('X')\n",
    "\n",
    "probs = lasagne.layers.get_output(percentile, input_X, deterministic = True)\n",
    "y_predicted = np.argmax(probs, axis=1)\n",
    "\n",
    "#all network weights (shared variables)\n",
    "all_weights = lasagne.layers.get_all_params(percentile)\n",
    "print(all_weights)\n",
    "\n",
    "#Mean categorical crossentropy as a loss function - similar to logistic loss but for multiclass targets\n",
    "loss = lasagne.objectives.categorical_crossentropy(probs, target_y).mean()\n",
    "l2_penalty = regularize_layer_params(percentile, l2) * 1e-1\n",
    "l1_penalty = regularize_layer_params(percentile, l1) * 1e-2\n",
    "loss += l2_penalty + l1_penalty\n",
    "\n",
    "#prediction accuracy\n",
    "accuracy = lasagne.objectives.categorical_accuracy(probs, target_y).mean()\n",
    "\n",
    "#This function computes gradient AND composes weight updates just like you did earlier\n",
    "updates_sgd = lasagne.updates.adagrad(loss, all_weights, learning_rate=0.005)\n",
    "\n",
    "#function that computes loss and updates weights\n",
    "train_fun = theano.function([input_X, target_y], [loss, accuracy], updates = updates_sgd)\n",
    "\n",
    "#function that just computes accuracy\n",
    "accuracy_fun = theano.function([input_X, target_y],accuracy)\n",
    "\n",
    "num_epochs = 300 #amount of passes through the data\n",
    "\n",
    "batch_size = 100 #number of samples processed at each function call\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(f1_train, y_train, batch_size):\n",
    "        inputs, targets = batch\n",
    "        train_err_batch, train_acc_batch = train_fun(inputs, targets.astype(np.int32))\n",
    "        train_err += train_err_batch\n",
    "        train_acc += train_acc_batch\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(f1_val, y_val, batch_size):\n",
    "        inputs, targets = batch\n",
    "        val_acc += accuracy_fun(inputs, targets.astype(np.int32))\n",
    "        val_batches += 1\n",
    "\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "\n",
    "    print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  train accuracy:\\t\\t{:.2f} %\".format(\n",
    "        train_acc / train_batches * 100))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network deleted road, 5 classes, stacked with segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W, b, W, b, W, b]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Error allocating 603979776 bytes of device memory (out of memory).\nApply node that caused the error: GpuDot22(GpuDimShuffle{1,0}.0, GpuElemwise{Composite{(i0 + (i0 * sgn(i1)))}}[(0, 0)].0)\nToposort index: 54\nInputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(36864, 100), (100, 4096)]\nInputs strides: [(1, 36864), (4096, 1)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[GpuElemwise{Sqr}[(0, 0)](GpuDot22.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-7a80a87eb928>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mtrain_err_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[0mtrain_err\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain_err_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain_acc_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/user/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    910\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[0;32m    913\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/user/anaconda2/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/user/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 899\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    900\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Error allocating 603979776 bytes of device memory (out of memory).\nApply node that caused the error: GpuDot22(GpuDimShuffle{1,0}.0, GpuElemwise{Composite{(i0 + (i0 * sgn(i1)))}}[(0, 0)].0)\nToposort index: 54\nInputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(36864, 100), (100, 4096)]\nInputs strides: [(1, 36864), (4096, 1)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[GpuElemwise{Sqr}[(0, 0)](GpuDot22.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "with open('data_rem_road.pkl', 'rb') as f:\n",
    "    X_train, Seg_train, y_train, X_val, Seg_val, y_val, X_test, Seg_test, y_test = pickle.load(f)\n",
    "    \n",
    "with open('features_rem_road.pkl', 'rb') as f:\n",
    "    f1_train, f1_val, f1_test, f2_train, f2_val, f2_test = pickle.load(f)\n",
    "    \n",
    "f1_train = np.hstack((np.array(f1_train), np.array(f2_train)))\n",
    "f1_val = np.hstack((np.array(f1_val), np.array(f2_val)))\n",
    "    \n",
    "bins = [np.percentile(y_train, 0),\n",
    "        np.percentile(y_train, 25),\n",
    "        np.percentile(y_train, 50),\n",
    "        np.percentile(y_train, 75),\n",
    "        np.percentile(y_train, 100) + 1]\n",
    "\n",
    "y_train = np.digitize(y_train, bins) - 1\n",
    "y_val = np.digitize(y_val, bins) - 1\n",
    "y_test = np.digitize(y_test, bins) - 1\n",
    "\n",
    "input_layer = InputLayer((None, f1_train[0].shape[0]))\n",
    "ll1 = DenseLayer(input_layer, num_units=4096)\n",
    "dr1 = DropoutLayer(ll1, p=0.5)\n",
    "ll2 = DenseLayer(dr1, num_units=4096)\n",
    "dr3 = DropoutLayer(ll2, p=0.5)\n",
    "percentile = DenseLayer(dr3, num_units=len(set(y_train)), nonlinearity=softmax)\n",
    "\n",
    "target_y = T.vector(\"target Y integer\", dtype='int32')\n",
    "input_X = T.matrix('X')\n",
    "\n",
    "probs = lasagne.layers.get_output(percentile, input_X, deterministic = True)\n",
    "y_predicted = np.argmax(probs, axis=1)\n",
    "\n",
    "#all network weights (shared variables)\n",
    "all_weights = lasagne.layers.get_all_params(percentile)\n",
    "print(all_weights)\n",
    "\n",
    "#Mean categorical crossentropy as a loss function - similar to logistic loss but for multiclass targets\n",
    "loss = lasagne.objectives.categorical_crossentropy(probs, target_y).mean()\n",
    "l2_penalty = regularize_layer_params(percentile, l2) * 1e-2\n",
    "l1_penalty = regularize_layer_params(percentile, l1) * 1e-3\n",
    "loss += l2_penalty + l1_penalty\n",
    "\n",
    "#prediction accuracy\n",
    "accuracy = lasagne.objectives.categorical_accuracy(probs, target_y).mean()\n",
    "\n",
    "#This function computes gradient AND composes weight updates just like you did earlier\n",
    "updates_sgd = lasagne.updates.adagrad(loss, all_weights, learning_rate=0.01)\n",
    "\n",
    "#function that computes loss and updates weights\n",
    "train_fun = theano.function([input_X, target_y], [loss, accuracy], updates = updates_sgd)\n",
    "\n",
    "#function that just computes accuracy\n",
    "accuracy_fun = theano.function([input_X, target_y],accuracy)\n",
    "\n",
    "num_epochs = 30 #amount of passes through the data\n",
    "\n",
    "batch_size = 100 #number of samples processed at each function call\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(f1_train, y_train, batch_size):\n",
    "        inputs, targets = batch\n",
    "        train_err_batch, train_acc_batch = train_fun(inputs, targets.astype(np.int32))\n",
    "        train_err += train_err_batch\n",
    "        train_acc += train_acc_batch\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(f1_val, y_val, batch_size):\n",
    "        inputs, targets = batch\n",
    "        val_acc += accuracy_fun(inputs, targets.astype(np.int32))\n",
    "        val_batches += 1\n",
    "\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "\n",
    "    print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  train accuracy:\\t\\t{:.2f} %\".format(\n",
    "        train_acc / train_batches * 100))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network with road, 5 classes, stacked with segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W, b, W, b, W, b]\n",
      "Epoch 1 of 30 took 4.315s\n",
      "  training loss (in-iteration):\t\t4726.092065\n",
      "  train accuracy:\t\t24.38 %\n",
      "  validation accuracy:\t\t33.00 %\n",
      "Epoch 2 of 30 took 4.367s\n",
      "  training loss (in-iteration):\t\t11.885494\n",
      "  train accuracy:\t\t30.03 %\n",
      "  validation accuracy:\t\t26.00 %\n",
      "Epoch 3 of 30 took 4.157s\n",
      "  training loss (in-iteration):\t\t5.118199\n",
      "  train accuracy:\t\t30.03 %\n",
      "  validation accuracy:\t\t25.20 %\n",
      "Epoch 4 of 30 took 4.156s\n",
      "  training loss (in-iteration):\t\t4.719048\n",
      "  train accuracy:\t\t33.24 %\n",
      "  validation accuracy:\t\t25.00 %\n",
      "Epoch 5 of 30 took 4.154s\n",
      "  training loss (in-iteration):\t\t4.602650\n",
      "  train accuracy:\t\t33.83 %\n",
      "  validation accuracy:\t\t25.40 %\n",
      "Epoch 6 of 30 took 4.158s\n",
      "  training loss (in-iteration):\t\t4.511264\n",
      "  train accuracy:\t\t34.45 %\n",
      "  validation accuracy:\t\t29.20 %\n",
      "Epoch 7 of 30 took 4.156s\n",
      "  training loss (in-iteration):\t\t4.433514\n",
      "  train accuracy:\t\t35.31 %\n",
      "  validation accuracy:\t\t31.80 %\n",
      "Epoch 8 of 30 took 4.153s\n",
      "  training loss (in-iteration):\t\t4.364174\n",
      "  train accuracy:\t\t35.90 %\n",
      "  validation accuracy:\t\t33.00 %\n",
      "Epoch 9 of 30 took 4.321s\n",
      "  training loss (in-iteration):\t\t4.301553\n",
      "  train accuracy:\t\t36.66 %\n",
      "  validation accuracy:\t\t34.60 %\n",
      "Epoch 10 of 30 took 4.163s\n",
      "  training loss (in-iteration):\t\t4.242831\n",
      "  train accuracy:\t\t38.03 %\n",
      "  validation accuracy:\t\t36.00 %\n",
      "Epoch 11 of 30 took 4.158s\n",
      "  training loss (in-iteration):\t\t4.186211\n",
      "  train accuracy:\t\t40.17 %\n",
      "  validation accuracy:\t\t37.40 %\n",
      "Epoch 12 of 30 took 4.189s\n",
      "  training loss (in-iteration):\t\t4.131390\n",
      "  train accuracy:\t\t42.07 %\n",
      "  validation accuracy:\t\t37.60 %\n",
      "Epoch 13 of 30 took 4.163s\n",
      "  training loss (in-iteration):\t\t4.075547\n",
      "  train accuracy:\t\t43.79 %\n",
      "  validation accuracy:\t\t39.00 %\n",
      "Epoch 14 of 30 took 4.183s\n",
      "  training loss (in-iteration):\t\t4.020848\n",
      "  train accuracy:\t\t45.31 %\n",
      "  validation accuracy:\t\t40.00 %\n",
      "Epoch 15 of 30 took 4.165s\n",
      "  training loss (in-iteration):\t\t3.965067\n",
      "  train accuracy:\t\t47.62 %\n",
      "  validation accuracy:\t\t42.20 %\n",
      "Epoch 16 of 30 took 4.164s\n",
      "  training loss (in-iteration):\t\t3.908799\n",
      "  train accuracy:\t\t50.52 %\n",
      "  validation accuracy:\t\t42.60 %\n",
      "Epoch 17 of 30 took 4.170s\n",
      "  training loss (in-iteration):\t\t3.857314\n",
      "  train accuracy:\t\t53.24 %\n",
      "  validation accuracy:\t\t43.60 %\n",
      "Epoch 18 of 30 took 4.167s\n",
      "  training loss (in-iteration):\t\t3.806450\n",
      "  train accuracy:\t\t55.59 %\n",
      "  validation accuracy:\t\t43.20 %\n",
      "Epoch 19 of 30 took 4.179s\n",
      "  training loss (in-iteration):\t\t3.757564\n",
      "  train accuracy:\t\t57.03 %\n",
      "  validation accuracy:\t\t43.20 %\n",
      "Epoch 20 of 30 took 4.165s\n",
      "  training loss (in-iteration):\t\t3.713492\n",
      "  train accuracy:\t\t58.41 %\n",
      "  validation accuracy:\t\t42.40 %\n",
      "Epoch 21 of 30 took 4.181s\n",
      "  training loss (in-iteration):\t\t3.673273\n",
      "  train accuracy:\t\t59.66 %\n",
      "  validation accuracy:\t\t42.20 %\n",
      "Epoch 22 of 30 took 4.169s\n",
      "  training loss (in-iteration):\t\t3.635788\n",
      "  train accuracy:\t\t60.59 %\n",
      "  validation accuracy:\t\t43.00 %\n",
      "Epoch 23 of 30 took 4.188s\n",
      "  training loss (in-iteration):\t\t3.601693\n",
      "  train accuracy:\t\t61.66 %\n",
      "  validation accuracy:\t\t40.60 %\n",
      "Epoch 24 of 30 took 4.169s\n",
      "  training loss (in-iteration):\t\t3.569888\n",
      "  train accuracy:\t\t63.17 %\n",
      "  validation accuracy:\t\t41.60 %\n",
      "Epoch 25 of 30 took 4.192s\n",
      "  training loss (in-iteration):\t\t3.539712\n",
      "  train accuracy:\t\t63.79 %\n",
      "  validation accuracy:\t\t41.00 %\n",
      "Epoch 26 of 30 took 4.172s\n",
      "  training loss (in-iteration):\t\t3.510056\n",
      "  train accuracy:\t\t64.86 %\n",
      "  validation accuracy:\t\t41.40 %\n",
      "Epoch 27 of 30 took 4.164s\n",
      "  training loss (in-iteration):\t\t3.482480\n",
      "  train accuracy:\t\t66.41 %\n",
      "  validation accuracy:\t\t40.20 %\n",
      "Epoch 28 of 30 took 4.187s\n",
      "  training loss (in-iteration):\t\t3.455721\n",
      "  train accuracy:\t\t67.69 %\n",
      "  validation accuracy:\t\t40.80 %\n",
      "Epoch 29 of 30 took 4.164s\n",
      "  training loss (in-iteration):\t\t3.428972\n",
      "  train accuracy:\t\t68.83 %\n",
      "  validation accuracy:\t\t41.20 %\n",
      "Epoch 30 of 30 took 4.173s\n",
      "  training loss (in-iteration):\t\t3.419649\n",
      "  train accuracy:\t\t68.41 %\n",
      "  validation accuracy:\t\t41.20 %\n"
     ]
    }
   ],
   "source": [
    "with open('data_basic.pkl', 'rb') as f:\n",
    "    X_train, Seg_train, y_train, X_val, Seg_val, y_val, X_test, Seg_test, y_test = pickle.load(f)\n",
    "    \n",
    "with open('features_basic.pkl', 'rb') as f:\n",
    "    f1_train, f1_val, f1_test, f2_train, f2_val, f2_test = pickle.load(f)\n",
    "    \n",
    "f1_train = np.hstack((np.array(f1_train), np.array(f2_train)))\n",
    "f1_val = np.hstack((np.array(f1_val), np.array(f2_val)))\n",
    "    \n",
    "bins = [np.percentile(y_train, 0),\n",
    "        np.percentile(y_train, 25),\n",
    "        np.percentile(y_train, 50),\n",
    "        np.percentile(y_train, 75),\n",
    "        np.percentile(y_train, 100) + 1]\n",
    "\n",
    "y_train = np.digitize(y_train, bins) - 1\n",
    "y_val = np.digitize(y_val, bins) - 1\n",
    "y_test = np.digitize(y_test, bins) - 1\n",
    "\n",
    "input_layer = InputLayer((None, f1_train[0].shape[0]))\n",
    "ll1 = DenseLayer(input_layer, num_units=4096)\n",
    "dr1 = DropoutLayer(ll1, p=0.5)\n",
    "ll2 = DenseLayer(dr1, num_units=4096)\n",
    "dr3 = DropoutLayer(ll2, p=0.5)\n",
    "percentile = DenseLayer(dr3, num_units=len(set(y_train)), nonlinearity=softmax)\n",
    "\n",
    "target_y = T.vector(\"target Y integer\", dtype='int32')\n",
    "input_X = T.matrix('X')\n",
    "\n",
    "probs = lasagne.layers.get_output(percentile, input_X, deterministic = True)\n",
    "y_predicted = np.argmax(probs, axis=1)\n",
    "\n",
    "#all network weights (shared variables)\n",
    "all_weights = lasagne.layers.get_all_params(percentile)\n",
    "print(all_weights)\n",
    "\n",
    "#Mean categorical crossentropy as a loss function - similar to logistic loss but for multiclass targets\n",
    "loss = lasagne.objectives.categorical_crossentropy(probs, target_y).mean()\n",
    "l2_penalty = regularize_layer_params(percentile, l2) * 1e-1\n",
    "l1_penalty = regularize_layer_params(percentile, l1) * 1e-2\n",
    "loss += l2_penalty + l1_penalty\n",
    "\n",
    "#prediction accuracy\n",
    "accuracy = lasagne.objectives.categorical_accuracy(probs, target_y).mean()\n",
    "\n",
    "#This function computes gradient AND composes weight updates just like you did earlier\n",
    "updates_sgd = lasagne.updates.adagrad(loss, all_weights, learning_rate=0.01)\n",
    "\n",
    "#function that computes loss and updates weights\n",
    "train_fun = theano.function([input_X, target_y], [loss, accuracy], updates = updates_sgd)\n",
    "\n",
    "#function that just computes accuracy\n",
    "accuracy_fun = theano.function([input_X, target_y],accuracy)\n",
    "\n",
    "num_epochs = 30 #amount of passes through the data\n",
    "\n",
    "batch_size = 100 #number of samples processed at each function call\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(f1_train, y_train, batch_size):\n",
    "        inputs, targets = batch\n",
    "        train_err_batch, train_acc_batch = train_fun(inputs, targets.astype(np.int32))\n",
    "        train_err += train_err_batch\n",
    "        train_acc += train_acc_batch\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(f1_val, y_val, batch_size):\n",
    "        inputs, targets = batch\n",
    "        val_acc += accuracy_fun(inputs, targets.astype(np.int32))\n",
    "        val_batches += 1\n",
    "\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "\n",
    "    print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  train accuracy:\\t\\t{:.2f} %\".format(\n",
    "        train_acc / train_batches * 100))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
