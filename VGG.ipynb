{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 1: Tesla K40m (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import NonlinearityLayer\n",
    "from lasagne.layers import DropoutLayer\n",
    "from lasagne.layers import Pool2DLayer as PoolLayer\n",
    "from lasagne.layers.dnn import Conv2DDNNLayer as ConvLayer\n",
    "from lasagne.nonlinearities import softmax\n",
    "from theano import function\n",
    "from scipy.misc import imread\n",
    "from data_preprocessing import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lasagne.regularization import regularize_layer_params_weighted, l2, l1, regularize_layer_params\n",
    "\n",
    "import sklearn\n",
    "import theano\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import theano.tensor as T\n",
    "#import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import lasagne\n",
    "import itertools\n",
    "\n",
    "#%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MEAN_VALUES = np.array([104, 117, 123], dtype=np.float32).reshape(1, 3, 1, 1)\n",
    " \n",
    "def preprocess(img):\n",
    "    return np.rollaxis(img, 2)[::-1][None] - MEAN_VALUES\n",
    "\n",
    "\n",
    "def deprocess(img):\n",
    "    return np.transpose((img + MEAN_VALUES)[0, ::-1], (1, 2, 0))\n",
    "\n",
    "\n",
    "def featurize(X):\n",
    "    data = [None] * len(X)\n",
    "\n",
    "    for i, img in enumerate(X):\n",
    "        img = proportional_resize(img)\n",
    "        data[i] = features(preprocess(img)).ravel()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_simple_model(input_shape):\n",
    "    net = {}\n",
    "    \n",
    "    net['input'] = InputLayer((None, input_shape[2], input_shape[0], input_shape[1]))\n",
    "    \n",
    "    net['conv1_1'] = ConvLayer(net['input'], 64, 3, pad=1, flip_filters=False)\n",
    "    net['conv1_2'] = ConvLayer(net['conv1_1'], 64, 3, pad=1, flip_filters=False)\n",
    "    net['pool1'] = PoolLayer(net['conv1_2'], 2)\n",
    "    net['conv2_1'] = ConvLayer(net['pool1'], 128, 3, pad=1, flip_filters=False)\n",
    "    net['conv2_2'] = ConvLayer(net['conv2_1'], 128, 3, pad=1, flip_filters=False)\n",
    "    net['pool2'] = PoolLayer(net['conv2_2'], 2)\n",
    "    net['conv3_1'] = ConvLayer(net['pool2'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['conv3_2'] = ConvLayer(net['conv3_1'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['conv3_3'] = ConvLayer(net['conv3_2'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['conv3_4'] = ConvLayer(net['conv3_3'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['pool3'] = PoolLayer(net['conv3_4'], 2)\n",
    "    net['conv4_1'] = ConvLayer(net['pool3'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv4_2'] = ConvLayer(net['conv4_1'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv4_3'] = ConvLayer(net['conv4_2'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv4_4'] = ConvLayer(net['conv4_3'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['pool4'] = PoolLayer(net['conv4_4'], 2)\n",
    "    net['conv5_1'] = ConvLayer(net['pool4'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv5_2'] = ConvLayer(net['conv5_1'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv5_3'] = ConvLayer(net['conv5_2'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv5_4'] = ConvLayer(net['conv5_3'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['pool5'] = PoolLayer(net['conv5_4'], 2)\n",
    "    \n",
    "    \n",
    "    net['fc6'] = DenseLayer(net['pool5'], num_units=4096)\n",
    "    net['fc6_dropout'] = DropoutLayer(net['fc6'], p=0.5)\n",
    "    net['fc7'] = DenseLayer(net['fc6_dropout'], num_units=4096)\n",
    "    net['fc7_dropout'] = DropoutLayer(net['fc7'], p=0.5)\n",
    "    net['fc8'] = DenseLayer(net['fc7_dropout'], num_units=1000, nonlinearity=None)\n",
    "    net['prob'] = NonlinearityLayer(net['fc8'], softmax)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained net params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('vgg19.pkl', 'rb') as f:\n",
    "    params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_dir = 'leftImg8bit'\n",
    "images_path = os.path.join(CITYSCAPESPATH, img_dir)\n",
    "\n",
    "first_img_path = [os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser(images_path)) for f in fn][0]\n",
    "img = imread(first_img_path)\n",
    "first_img = proportional_resize(img)\n",
    "net = build_simple_model(first_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_vgg_layer = net['pool5']\n",
    "lasagne.layers.set_all_param_values(last_vgg_layer, params['param values'][:32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_X = T.tensor4('X')\n",
    "\n",
    "output = lasagne.layers.get_output(last_vgg_layer, input_X, deterministic = True)\n",
    "features = function([input_X], output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(modes, *args, **kwargs):\n",
    "    cities = get_cities(modes=['train'])\n",
    "    dataset = prepare_dataset(\n",
    "            itertools.chain(*[zip(ReadFilePaths(mode, city, 'leftImg8bit'),\n",
    "                                  ReadFilePaths(mode, city, 'gtCoarse', 'gtCoarse_color.png'),\n",
    "                                  ReadFilePaths(mode, city, 'disparity'))\n",
    "                            for mode in modes for city in cities[mode]]), *args, **kwargs)\n",
    "    return zip(*dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.7 s, sys: 4.17 s, total: 20.9 s\n",
      "Wall time: 20.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_filename = 'data_basic.pkl'\n",
    "\n",
    "if os.path.exists(data_filename):\n",
    "    with open(data_filename, 'rb') as f:\n",
    "        X_train, Seg_train, y_train, X_val, Seg_val, y_val, X_test, Seg_test, y_test = pickle.load(f)\n",
    "else:\n",
    "    X_val, Seg_val, y_val = load_data(['val'], False, 7)\n",
    "    X_train, Seg_train, y_train = load_data(['train'], False, 10)\n",
    "    X_test, Seg_test, y_test = load_data(['test'], False, 7)\n",
    "\n",
    "    X_val = np.array(X_val)\n",
    "    y_val = np.array(y_val)\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    Seg_test = np.array(Seg_test)\n",
    "    Seg_train = np.array(Seg_train)\n",
    "    Seg_val = np.array(Seg_val)\n",
    "    \n",
    "    with open(data_filename, 'wb') as f:\n",
    "        pickle.dump((X_train, Seg_train, y_train, X_val, Seg_val, y_val, X_test, Seg_test, y_test), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.5 s, sys: 4.47 s, total: 25 s\n",
      "Wall time: 25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_filename = 'data_rem_road.pkl'\n",
    "\n",
    "if os.path.exists(data_filename):\n",
    "    with open(data_filename, 'rb') as f:\n",
    "        X_train, Seg_train, y_train, X_val, Seg_val, y_val, X_test, Seg_test, y_test = pickle.load(f)\n",
    "else:\n",
    "    X_val, Seg_val, y_val = load_data(['val'], True, 10)\n",
    "    X_train, Seg_train, y_train = load_data(['train'], True, 10)\n",
    "    X_test, Seg_test, y_test = load_data(['test'], True, 10)\n",
    "\n",
    "    X_val = np.array(X_val)\n",
    "    y_val = np.array(y_val)\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    Seg_test = np.array(Seg_test)\n",
    "    Seg_train = np.array(Seg_train)\n",
    "    Seg_val = np.array(Seg_val)\n",
    "\n",
    "    with open(data_filename, 'wb') as f:\n",
    "        pickle.dump((X_train, Seg_train, y_train, X_val, Seg_val, y_val, X_test, Seg_test, y_test), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_filename = 'data_huge.pkl'\n",
    "\n",
    "if os.path.exists(data_filename):\n",
    "    with open(data_filename, 'rb') as f:\n",
    "        X_train, Seg_train, y_train, X_val, Seg_val, y_val, X_test, Seg_test, y_test = pickle.load(f)\n",
    "else:\n",
    "#     X_val, Seg_val, y_val = load_data(['val'], False, 10)\n",
    "    X_train, Seg_train, y_train = load_data(['train'], False, 10)\n",
    "#     X_test, Seg_test, y_test = load_data(['test'], False, 10)\n",
    "\n",
    "    X_val = np.array(X_val)\n",
    "    y_val = np.array(y_val)\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    Seg_test = np.array(Seg_test)\n",
    "    Seg_train = np.array(Seg_train)\n",
    "    Seg_val = np.array(Seg_val)\n",
    "    \n",
    "    with open(data_filename, 'wb') as f:\n",
    "        pickle.dump((X_train, Seg_train, y_train, X_val, Seg_val, y_val, X_test, Seg_test, y_test), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min 11s, sys: 9min 59s, total: 31min 10s\n",
      "Wall time: 32min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f1_val = featurize(X_val)\n",
    "f1_train = featurize(X_train)\n",
    "f1_test = featurize(X_test)\n",
    "f2_val = featurize(Seg_val)\n",
    "f2_train = featurize(Seg_train)\n",
    "f2_test = featurize(Seg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_filename = 'data_huge_rem_road.pkl'\n",
    "\n",
    "if os.path.exists(data_filename):\n",
    "    with open(data_filename, 'rb') as f:\n",
    "        X_train, Seg_train, y_train, X_val, Seg_val, y_val, X_test, Seg_test, y_test = pickle.load(f)\n",
    "else:\n",
    "#     X_val, Seg_val, y_val = load_data(['val'], False, 10)\n",
    "    X_train, Seg_train, y_train = load_data(['train'], True, 10)\n",
    "#     X_test, Seg_test, y_test = load_data(['test'], False, 10)\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    Seg_train = np.array(Seg_train)\n",
    "\n",
    "    with open(data_filename, 'wb') as f:\n",
    "        pickle.dump((X_train, Seg_train, y_train, X_val, Seg_val, y_val, X_test, Seg_test, y_test), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 11s, sys: 8min 45s, total: 27min 56s\n",
      "Wall time: 28min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f1_train = featurize(X_train)\n",
    "f2_train = featurize(Seg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2975, (18432,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f1_train), f1_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('features_huge_rem_road.pkl', 'wb') as f:\n",
    "    cPickle.dump((f1_train, f2_train), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load Huge without road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 49s, sys: 33.9 s, total: 11min 23s\n",
      "Wall time: 11min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open('data_huge_rem_road.pkl', 'rb') as f:\n",
    "    _, _, y_train, _, _, y_val, _, _, y_test = pickle.load(f)\n",
    "\n",
    "with open('features_rem_road.pkl', 'rb') as f:\n",
    "    _, f1_val, f1_test, _, f2_val, f2_test = pickle.load(f)\n",
    "\n",
    "with open('features_huge_rem_road.pkl', 'rb') as f:\n",
    "    f1_train, f2_train = cPickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('features_huge.pkl', 'wb') as f:\n",
    "    cPickle.dump((f1_train, f2_train), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('features_huge.pkl', 'rb') as f:\n",
    "    f1_train, f2_train = cPickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('features_rem_road.pkl', 'wb') as f:\n",
    "    pickle.dump((f1_train, f1_val, f1_test, f2_train, f2_val, f2_test), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('features_rem_road.pkl', 'rb') as f:\n",
    "    f1_train, f1_val, f1_test, f2_train, f2_val, f2_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('features_basic.pkl', 'wb') as f:\n",
    "    pickle.dump((f1_train, f1_val, f1_test, f2_train, f2_val, f2_test), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('features_basic.pkl', 'rb') as f:\n",
    "    f1_train, f1_val, f1_test, f2_train, f2_val, f2_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  16.,   49.,   88.,  163.,  109.,  125.,  120.,  113.,  127.,\n",
       "         106.,  132.,  134.,  115.,  195.,  295.,  368.,  252.,  131.,\n",
       "         125.,  212.]),\n",
       " array([  14. ,   19.6,   25.2,   30.8,   36.4,   42. ,   47.6,   53.2,\n",
       "          58.8,   64.4,   70. ,   75.6,   81.2,   86.8,   92.4,   98. ,\n",
       "         103.6,  109.2,  114.8,  120.4,  126. ]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFOBJREFUeJzt3XGsnXd93/H3J7hJkzJc0y6+bQyxWSh1kFhAitstmnY2\nWpNQyY46KQ1UVdIMCSmjRN1UYWeafNdVKkGCionljzUQeSipMXQ0TkUTY4VTRCWStImXgN3ME7Mx\nLr5shWXNIiGbfPfHeRJOLte+555z7j3n3Of9ko78nN95nvN87/G9n/M7v+d5zi9VhSSpHS6ZdAGS\npLVj6EtSixj6ktQihr4ktYihL0ktYuhLUosMHPpJLknyVJJDzf1NSQ4neS7Jo0k29q27N8mJJMeT\n7FyNwiVJK7eSnv5dwLG++3uAI1X1FuAxYC9AkmuBW4DtwE3AvUkynnIlSaMYKPSTbAHeDdzX17wb\n2N8s7wdubpZ3AQeq6nxVnQROADvGUq0kaSSD9vT/APgdoP/y3c1VtQBQVWeBK5v2q4DTfeudadok\nSRO2bOgn+RVgoaqOAhcbpvH7HCRpym0YYJ0bgF1J3g1cDvy9JJ8GzibZXFULSeaA7zTrnwHe0Lf9\nlqbtVZL4JiFJQ6iqoY+TLtvTr6q7q+qNVfUm4Fbgsar6DeBh4PZmtduAh5rlQ8CtSS5Nsg24Bnji\nAs89s7d9+/ZNvAbrn3wdbax/lmtfD/WPapCe/oV8GDiY5A7gFL0zdqiqY0kO0jvT5xxwZ42jUknS\nyFYU+lX158CfN8vfBX7pAuv9PvD7I1cnSRorr8gdUqfTmXQJI7H+yZrl+me5dpj9+keVSY28JHHU\nR5JWKAm1mgdyJUnrh6EvSS1i6EtSixj6ktQihr4ktYihL0ktYuhLUosY+pLUIoa+JLWIoS9JLWLo\nS1KLGPqSLmpubitJVnSbm9s66bJ1AX7hmqSLSsLKZ0PNWCb80I/yC9ckSQMz9CWpRQx9SWoRQ1+S\nWmTZ0E9yWZLHkzyd5Nkk+5r2fUm+leSp5nZj3zZ7k5xIcjzJztX8ASRJgxvo7J0kV1TVi0leA/wF\n8EHgJuDvqupji9bdDjwIXA9sAY4Ab158qo5n70izwbN3psuanL1TVS82i5cBG/jhb8BSO94NHKiq\n81V1EjgB7Bi2QEnS+AwU+kkuSfI0cBb4YlU92Tz0gSRHk9yXZGPTdhVwum/zM02bJGnCBu3pv1RV\nb6c3XLMjybXAvcCbquo6em8GH129MiVJ47BhJStX1f9N0gVuXDSW/4fAw83yGeANfY9tadp+xPz8\n/CvLnU6HTqezknIkad3rdrt0u92xPd+yB3KT/DRwrqqeT3I58CjwYeCpqjrbrPPbwPVV9d7mU8AD\nwC/QG9b5Ih7IlWaWB3Kny6gHcgfp6f8MsD/JJfSGgz5TVV9I8l+SXAe8BJwE3g9QVceSHASOAeeA\nO013SZoOfuGapIuypz9d/MI1SdLADH1JahFDX5JaxNCXpBYx9CWpRQx9SWoRQ1+SWsTQl6QWMfQl\nqUUMfUlqEUNfklrE0JekFjH0JalFDH1JahFDX5JaxNCXpBYx9CWpRQx9SWoRQ1+SWmTZ0E9yWZLH\nkzyd5Nkk+5r2TUkOJ3kuyaNJNvZtszfJiSTHk+xczR9AkjS4gSZGT3JFVb2Y5DXAXwAfBP4F8LdV\n9ZEkHwI2VdWeJNcCDwDXA1uAI8CbF8+C7sTo0mxwYvTpsiYTo1fVi83iZcAGer8Bu4H9Tft+4OZm\neRdwoKrOV9VJ4ASwY9gCJUnjM1DoJ7kkydPAWeCLVfUksLmqFgCq6ixwZbP6VcDpvs3PNG2SpAnb\nMMhKVfUS8PYkrwM+n+St/OjnvRV/lpufn39ludPp0Ol0VvoUkrSudbtdut3u2J5voDH9V22Q/Dvg\nReB9QKeqFpLMAV+qqu1J9gBVVfc06z8C7Kuqxxc9j2P60gxwTH+6rPqYfpKffvnMnCSXA78MHAcO\nAbc3q90GPNQsHwJuTXJpkm3ANcATwxYoSRqfQYZ3fgbYn+QSem8Sn6mqLyT5KnAwyR3AKeAWgKo6\nluQgcAw4B9xpl16avLm5rSwsnJp0GZqwFQ/vjG3HDu9Ia2q4YRoAh3emyZqcsilJWh8MfUlqEUNf\nklrE0JekFjH0JalFDH1JahFDX5JaxNCXpBYx9CWpRQx9SWoRQ1+SWsTQl6QWMfQlqUUMfUlqEUNf\nklrE0JekFjH0JalFDH1JahFDX5JaZNnQT7IlyWNJvp7k2SS/1bTvS/KtJE81txv7ttmb5ESS40l2\nruYPIEka3LIToyeZA+aq6miS1wJ/BewGfg34u6r62KL1twMPAtcDW4AjwJsXz4LuxOjS2nJi9PVh\n1SdGr6qzVXW0WX4BOA5c9fL+l9hkN3Cgqs5X1UngBLBj2AIlSeOzojH9JFuB64DHm6YPJDma5L4k\nG5u2q4DTfZud4YdvEpJa4TKSrOg2N7d10kW3woZBV2yGdj4H3FVVLyS5F/jdqqokvwd8FHjfSnY+\nPz//ynKn06HT6axkc0lT6/usdEhoYWHoEYt1rdvt0u12x/Z8y47pAyTZAPwp8GdV9fElHr8aeLiq\n3pZkD1BVdU/z2CPAvqp6fNE2julLa2itx/Q9DrA6Vn1Mv/Ep4Fh/4DcHeF/2q8DXmuVDwK1JLk2y\nDbgGeGLYAiVJ47Ps8E6SG4BfB55N8jS9t++7gfcmuQ54CTgJvB+gqo4lOQgcA84Bd9qll6TpMNDw\nzqrs2OEdaU05vLM+rNXwjiRpHTD0JalFDH1JahFDX5JaxNCXpBYx9CWpRQx9SWoRQ1+SWsTQl6QW\nMfQlqUUMfUlqEUNfklrE0JekFjH0JalFDH1JahFDX5JaxNCXpBYx9CW1ztzcVpKs+DY3t3XSpY/M\n6RKllnC6xL49jfBaTDq3Vn26xCRbkjyW5OtJnk3ywaZ9U5LDSZ5L8miSjX3b7E1yIsnxJDuHLU6S\nNF7L9vSTzAFzVXU0yWuBvwJ2A78J/G1VfSTJh4BNVbUnybXAA8D1wBbgCPDmxd16e/rS2rKn37cn\ne/oXVlVnq+pos/wCcJxemO8G9jer7QdubpZ3AQeq6nxVnQROADuGLVCSND4rOpCbZCtwHfBVYHNV\nLUDvjQG4slntKuB032ZnmjZJ0oRtGHTFZmjnc8BdVfVCksWfcVb8mWd+fv6V5U6nQ6fTWelTSNK6\n1u126Xa7Y3u+gc7eSbIB+FPgz6rq403bcaBTVQvNuP+Xqmp7kj1AVdU9zXqPAPuq6vFFz+mYvrSG\nHNPv25Nj+sv6FHDs5cBvHAJub5ZvAx7qa781yaVJtgHXAE8MW6AkaXwGOXvnBuDLwLP03hoLuJte\nkB8E3gCcAm6pqv/TbLMX+JfAOXrDQYeXeF57+tKQ5ua2srBwaogt7elDu3v6XpwlzaDhQsvhnVf2\n1OLQ92sYJKlFDH1JahFDX5JaxNCXpBYx9CWpRQx9SWoRQ1+SWsTQl6QWMfQlqUUMfUlqEUNfklrE\n0JekFjH0JalFDH1JahFDX5JaxNCXpBYx9Kfc3NxWkqzoNje3ddJlS5pSzpw15YadIcnXdn1z5qzR\nOHOWJKkVlg39JJ9MspDkmb62fUm+leSp5nZj32N7k5xIcjzJztUqXJK0coP09O8H3rVE+8eq6h3N\n7RGAJNuBW4DtwE3Avel9jpIkTYFlQ7+qvgJ8b4mHlgrz3cCBqjpfVSeBE8COkSqUJI3NKGP6H0hy\nNMl9STY2bVcBp/vWOdO0SZKmwIYht7sX+N2qqiS/B3wUeN9Kn2R+fv6V5U6nQ6fTGbIcSVqfut0u\n3W53bM830CmbSa4GHq6qt13ssSR7gKqqe5rHHgH2VdXjS2znKZsD8JRNLcVTNkfjKZsD7Ie+Mfwk\nc32P/SrwtWb5EHBrkkuTbAOuAZ4YtjhJ0ngtO7yT5EGgA/xUkm8C+4B/luQ64CXgJPB+gKo6luQg\ncAw4B9xpd16SpodX5E45h3e0FId3RuPwjiSpFQx9SWoRQ1+SWsTQl6QWMfSlMRlm7gPnP9BaG/aK\nXGldm5vbysLCqSG2XPmZHQsLfieh1o49fWkJvcCvFd40msv8pLQG7OlLmhLfx09Kq8+evmaG8wVL\no/OK3Cm3llfkDjOOvXnz1Zw9e3LF+xrGWr4Wa33F60prXK9X5A5X34/T+5SwUu28ItfQn3KzEHTT\nfem8od+/n/UZ+tP9fzVufg2DJGlghr5G5BkX0izx7B2NyDMupFliT1+SWsSevjRxlzUHZqXVZ+hr\nQgy6HxpmiMzXTsMx9DUhBp00CYb+umQvWtLSlj2Qm+STSRaSPNPXtinJ4STPJXk0yca+x/YmOZHk\neJKdq1W4LublXrRfGCbp1QY5e+d+4F2L2vYAR6rqLcBjwF6AJNcCtwDbgZuAe2OXUxM13HUE0nq1\nbOhX1VeA7y1q3g3sb5b3Azc3y7uAA1V1vqpOAieAHeMpVRqGn3qkfsOep39lVS0AVNVZ4Mqm/Srg\ndN96Z5o2SdIUGNeB3KG6RvPz868sdzodOp3OmMqRpPWh2+3S7XbH9nwDfctmkquBh6vqbc3940Cn\nqhaSzAFfqqrtSfYAVVX3NOs9AuyrqseXeE6/ZXMA6/PbFNdyX9Ne31ruy/rGsa9J59ZafctmePVJ\n0oeA25vl24CH+tpvTXJpkm3ANcATwxYnSRqvZYd3kjwIdICfSvJNYB/wYeCzSe4ATtE7Y4eqOpbk\nIHAMOAfcaXdekqaHk6hMOYd3JrHNet2X9Y1jX5POLSdRkSQNzNCXpBYx9NfQ3NxWrwyVNFGO6a+h\ntRufn42xUV+Ltd6X9Y1jX5POLcf0JUkDM/QlqUUMfUlqEUNfklrE0JekFjH0JalFDH1JahFDX5Ja\nxNCXpBYx9CWpRQx9SWoRQ1+SWsTQl6QWMfQlqUWWnSP3YpKcBJ4HXgLOVdWOJJuAzwBXAyeBW6rq\n+RHrlCSNwag9/ZeATlW9vap2NG17gCNV9RbgMWDviPuQJI3JqKGfJZ5jN7C/Wd4P3DziPiRJYzJq\n6BfwxSRPJnlf07a5qhYAquoscOWI+5AkjclIY/rADVX17SR/Hzic5Dl+dA6yds2JKElTbKTQr6pv\nN//+ryR/AuwAFpJsrqqFJHPAdy60/fz8/CvLnU6HTqczSjlrZm5uKwsLpyZdhqQW6Ha7dLvdsT3f\n0BOjJ7kCuKSqXkjyE8Bh4N8D7wS+W1X3JPkQsKmq9iyx/cxOjD7cBOfgBNOT2Ne017eW+7K+cexr\n0rk16sToo/T0NwOfT1LN8zxQVYeT/CVwMMkdwCnglhH2IUkao6F7+iPv2J7+lG2zXvc17fWt5b6s\nbxz7mnRujdrT94pcSWoRQ1+SWsTQl6QWMfQlqUUMfUlqEUNfklrE0JekFjH0JalFDH1JahFDX5Ja\nxNCXpBYx9CWpRQx9SWoRQ1+SWmTU6RJn2mc/+yccOPD5SZchSWum1aH/iU98ii9/eRvwjhVs9dRq\nlSNJq67Vod/zTmDXCtbfBPzHVapFklaXY/qS1CKGviS1yKqFfpIbk/x1kv+e5EOrtR9J0uBWJfST\nXAJ8AngX8FbgPUl+fjX2NTndSRcwou6kCxhRd9IFjKg76QJG0J10ASPqTrqAiVqtnv4O4ERVnaqq\nc8ABYPcq7WtCupMuYETdSRcwou6kCxhRd9IFjKA76QJG1J10ARO1WqF/FXC67/63mjZJ0gS1+pTN\nyy77Ma644j+wYcMfDrzN+fNnefHFVSxKklZRqmr8T5r8IjBfVTc29/cAVVX39K0z/h1LUgtUVYbd\ndrVC/zXAc/SufPo28ATwnqo6PvadSZIGtirDO1X1gyQfAA7TO27wSQNfkiZvVXr6kqTpNJErcmft\nwq0kW5I8luTrSZ5N8sGmfVOSw0meS/Joko2TrvVCklyS5Kkkh5r7s1T7xiSfTXK8+T/4hRmr/7eT\nfC3JM0keSHLpNNef5JNJFpI809d2wXqT7E1yovn/2TmZqn/oAvV/pKnvaJI/TvK6vsemvv6+x/5N\nkpeSvL6vbUX1r3noz+iFW+eBf11VbwX+EfCvmpr3AEeq6i3AY8DeCda4nLuAY333Z6n2jwNfqKrt\nwD8E/poZqT/JzwK/Bbyjqt5Gb0j1PUx3/ffT+/vst2S9Sa4FbgG2AzcB9yYZ+iDjmCxV/2HgrVV1\nHXCC2aufJFuAXwZO9bVtZ4X1T6KnP3MXblXV2ao62iy/ABwHttCre3+z2n7g5slUeHHNL8u7gfv6\nmmel9tcB/6Sq7geoqvNV9TwzUn/jNcBPJNkAXA6cYYrrr6qvAN9b1HyhencBB5r/l5P0AnXHWtR5\nIUvVX1VHquql5u5X6f39wozU3/gD4HcWte1mhfVPIvRn+sKtJFuB6+j94myuqgXovTEAV06usot6\n+Zel/wDOrNS+DfjfSe5vhqf+c5IrmJH6q+pvgI8C36QX9s9X1RFmpP4+V16g3sV/z2eY/r/nO4Av\nNMszUX+SXcDpqnp20UMrrt9v2VyBJK8FPgfc1fT4Fx8Fn7qj4kl+BVhoPqlc7GPf1NXe2EBvlpv/\nVFXvAP4fvaGGqX/tAZL8JL3e2NXAz9Lr8f86M1L/RcxavQAk+bfAuar6o0nXMqgklwN3A/vG8XyT\nCP0zwBv77m9p2qZa89H8c8Cnq+qhpnkhyebm8TngO5Oq7yJuAHYl+QbwR8A/T/Jp4OwM1A69T4Kn\nq+ovm/t/TO9NYBZee4BfAr5RVd+tqh8Anwf+MbNT/8suVO8Z4A19603t33OS2+kNc763r3kW6v8H\nwFbgvyX5n/RqfCrJlQyRp5MI/SeBa5JcneRS4Fbg0ATqWKlPAceq6uN9bYeA25vl24CHFm80aVV1\nd1W9sareRO+1fqyqfgN4mCmvHaAZUjid5OeapncCX2cGXvvGN4FfTPLjzQG2d9I7oD7t9YdXfzK8\nUL2HgFubM5K2AdfQuxhz0l5Vf5Ib6Q1x7qqq7/etN/X1V9XXqmquqt5UVdvodYTeXlXfoVf/r62o\n/qpa8xtwI70rdk8AeyZRwwrrvQH4AXAUeJreRLk3Aq8HjjQ/y2HgJydd6zI/xz8FDjXLM1M7vTN2\nnmxe//8KbJyx+vfRO/j/DL2DoD82zfUDDwJ/A3yf3pvWb9KbJ3TJeumdCfM/mp9x55TWf4LeWS9P\nNbd7Z6n+RY9/A3j9sPV7cZYktYgHciWpRQx9SWoRQ1+SWsTQl6QWMfQlqUUMfUlqEUNfklrE0Jek\nFvn/fDdz69A4RXMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd751f4cf50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 60, 105,  42, ...,  83,  18,  50], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = [np.percentile(y_train, 0),\n",
    "        np.percentile(y_train, 50),\n",
    "        np.percentile(y_train, 100) + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14.0, 57.0, 89.0, 103.0, 127.0]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = np.digitize(y_train, bins) - 1\n",
    "y_val = np.digitize(y_val, bins) - 1\n",
    "y_test = np.digitize(y_test, bins) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 739.,    0.,    0.,  715.,    0.,    0.,  721.,    0.,    0.,  800.]),\n",
       " array([ 0. ,  0.3,  0.6,  0.9,  1.2,  1.5,  1.8,  2.1,  2.4,  2.7,  3. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEACAYAAACwB81wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd6f3844d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With the road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73199999999999998"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.005, penalty='l1')\n",
    "clf.fit(f1_train, y_train).score(f1_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With the road + segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82399999999999995"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.005, penalty='l1')\n",
    "clf.fit(np.hstack((np.array(f1_train), np.array(f2_train))), y_train).score(np.hstack((np.array(f1_val), np.array(f2_val))), y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Road deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88400000000000001"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.005, penalty='l1')\n",
    "clf.fit(f1_train, y_train).score(f1_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road deleted + segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86799999999999999"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.005, penalty='l1')\n",
    "clf.fit(np.hstack((np.array(f1_train), np.array(f2_train))), y_train).score(np.hstack((np.array(f1_val), np.array(f2_val))), y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network deleted road, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W, b, W, b, W, b, W, b, W, b, W, b]\n",
      "Epoch 1 of 30 took 1.998s\n",
      "  training loss (in-iteration):\t\t3749.619600\n",
      "  train accuracy:\t\t28.59 %\n",
      "  validation accuracy:\t\t26.00 %\n",
      "Epoch 2 of 30 took 2.015s\n",
      "  training loss (in-iteration):\t\t3.113019\n",
      "  train accuracy:\t\t32.24 %\n",
      "  validation accuracy:\t\t46.60 %\n",
      "Epoch 3 of 30 took 1.982s\n",
      "  training loss (in-iteration):\t\t2.176733\n",
      "  train accuracy:\t\t45.90 %\n",
      "  validation accuracy:\t\t49.40 %\n",
      "Epoch 4 of 30 took 2.010s\n",
      "  training loss (in-iteration):\t\t1.896570\n",
      "  train accuracy:\t\t52.72 %\n",
      "  validation accuracy:\t\t58.00 %\n",
      "Epoch 5 of 30 took 1.978s\n",
      "  training loss (in-iteration):\t\t1.765641\n",
      "  train accuracy:\t\t58.38 %\n",
      "  validation accuracy:\t\t52.20 %\n",
      "Epoch 6 of 30 took 2.000s\n",
      "  training loss (in-iteration):\t\t1.671071\n",
      "  train accuracy:\t\t63.17 %\n",
      "  validation accuracy:\t\t62.00 %\n",
      "Epoch 7 of 30 took 2.000s\n",
      "  training loss (in-iteration):\t\t1.551463\n",
      "  train accuracy:\t\t69.31 %\n",
      "  validation accuracy:\t\t55.20 %\n",
      "Epoch 8 of 30 took 2.111s\n",
      "  training loss (in-iteration):\t\t1.477413\n",
      "  train accuracy:\t\t71.52 %\n",
      "  validation accuracy:\t\t66.60 %\n",
      "Epoch 9 of 30 took 2.005s\n",
      "  training loss (in-iteration):\t\t1.404215\n",
      "  train accuracy:\t\t76.62 %\n",
      "  validation accuracy:\t\t59.40 %\n",
      "Epoch 10 of 30 took 1.980s\n",
      "  training loss (in-iteration):\t\t1.373313\n",
      "  train accuracy:\t\t76.55 %\n",
      "  validation accuracy:\t\t67.40 %\n",
      "Epoch 11 of 30 took 1.987s\n",
      "  training loss (in-iteration):\t\t1.343516\n",
      "  train accuracy:\t\t77.24 %\n",
      "  validation accuracy:\t\t60.80 %\n",
      "Epoch 12 of 30 took 2.008s\n",
      "  training loss (in-iteration):\t\t1.256678\n",
      "  train accuracy:\t\t81.34 %\n",
      "  validation accuracy:\t\t61.20 %\n",
      "Epoch 13 of 30 took 2.102s\n",
      "  training loss (in-iteration):\t\t1.214769\n",
      "  train accuracy:\t\t83.93 %\n",
      "  validation accuracy:\t\t66.20 %\n",
      "Epoch 14 of 30 took 1.999s\n",
      "  training loss (in-iteration):\t\t1.203365\n",
      "  train accuracy:\t\t84.66 %\n",
      "  validation accuracy:\t\t61.60 %\n",
      "Epoch 15 of 30 took 1.974s\n",
      "  training loss (in-iteration):\t\t1.129455\n",
      "  train accuracy:\t\t87.41 %\n",
      "  validation accuracy:\t\t67.00 %\n",
      "Epoch 16 of 30 took 2.126s\n",
      "  training loss (in-iteration):\t\t1.263559\n",
      "  train accuracy:\t\t85.00 %\n",
      "  validation accuracy:\t\t67.40 %\n",
      "Epoch 17 of 30 took 1.980s\n",
      "  training loss (in-iteration):\t\t1.062010\n",
      "  train accuracy:\t\t91.52 %\n",
      "  validation accuracy:\t\t65.40 %\n",
      "Epoch 18 of 30 took 1.974s\n",
      "  training loss (in-iteration):\t\t1.000695\n",
      "  train accuracy:\t\t93.72 %\n",
      "  validation accuracy:\t\t64.40 %\n",
      "Epoch 19 of 30 took 2.005s\n",
      "  training loss (in-iteration):\t\t0.974304\n",
      "  train accuracy:\t\t94.59 %\n",
      "  validation accuracy:\t\t64.00 %\n",
      "Epoch 20 of 30 took 1.980s\n",
      "  training loss (in-iteration):\t\t0.925185\n",
      "  train accuracy:\t\t96.62 %\n",
      "  validation accuracy:\t\t62.00 %\n",
      "Epoch 21 of 30 took 2.003s\n",
      "  training loss (in-iteration):\t\t0.937583\n",
      "  train accuracy:\t\t96.28 %\n",
      "  validation accuracy:\t\t62.60 %\n",
      "Epoch 22 of 30 took 1.997s\n",
      "  training loss (in-iteration):\t\t1.025416\n",
      "  train accuracy:\t\t93.21 %\n",
      "  validation accuracy:\t\t62.00 %\n",
      "Epoch 23 of 30 took 1.987s\n",
      "  training loss (in-iteration):\t\t1.056850\n",
      "  train accuracy:\t\t92.55 %\n",
      "  validation accuracy:\t\t63.80 %\n",
      "Epoch 24 of 30 took 1.997s\n",
      "  training loss (in-iteration):\t\t0.880320\n",
      "  train accuracy:\t\t98.07 %\n",
      "  validation accuracy:\t\t64.40 %\n",
      "Epoch 25 of 30 took 2.182s\n",
      "  training loss (in-iteration):\t\t0.861131\n",
      "  train accuracy:\t\t98.76 %\n",
      "  validation accuracy:\t\t64.80 %\n",
      "Epoch 26 of 30 took 2.169s\n",
      "  training loss (in-iteration):\t\t0.866686\n",
      "  train accuracy:\t\t98.07 %\n",
      "  validation accuracy:\t\t64.60 %\n",
      "Epoch 27 of 30 took 2.097s\n",
      "  training loss (in-iteration):\t\t0.839886\n",
      "  train accuracy:\t\t99.03 %\n",
      "  validation accuracy:\t\t64.80 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-d82e6a4058e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mtrain_err_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0mtrain_err\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain_err_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain_acc_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    813\u001b[0m                         s.storage[0] = s.type.filter(\n\u001b[0;32m    814\u001b[0m                             \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 815\u001b[1;33m                             allow_downcast=s.allow_downcast)\n\u001b[0m\u001b[0;32m    816\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/tensor/type.pyc\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, data, strict, allow_downcast)\u001b[0m\n\u001b[0;32m    148\u001b[0m                     \u001b[1;31m# data has to be converted.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m                     \u001b[1;31m# Check that this conversion is lossless\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m                     \u001b[0mconverted_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_asarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m                     \u001b[1;31m# We use the `values_eq` static function from TensorType\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m                     \u001b[1;31m# to handle NaN values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/misc/safe_asarray.pyc\u001b[0m in \u001b[0;36m_asarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Convert into dtype object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[1;31m# Note that dtype comparison must be done by comparing their `num`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# attribute. One cannot assume that two identical data types are pointers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib64/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \"\"\"\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open('data_rem_road.pkl', 'rb') as f:\n",
    "    X_train, Seg_train, y_train, X_val, Seg_val, y_val, X_test, Seg_test, y_test = pickle.load(f)\n",
    "    \n",
    "with open('features_rem_road.pkl', 'rb') as f:\n",
    "    f1_train, f1_val, f1_test, f2_train, f2_val, f2_test = pickle.load(f)\n",
    "    \n",
    "bins = [np.percentile(y_train, 0),\n",
    "        np.percentile(y_train, 25),\n",
    "        np.percentile(y_train, 50),\n",
    "        np.percentile(y_train, 75),\n",
    "        np.percentile(y_train, 100) + 1]\n",
    "\n",
    "y_train = np.digitize(y_train, bins) - 1\n",
    "y_val = np.digitize(y_val, bins) - 1\n",
    "y_test = np.digitize(y_test, bins) - 1\n",
    "\n",
    "input_layer = InputLayer((None, f1_train[0].shape[0]))\n",
    "ll1 = DenseLayer(input_layer, num_units=2048, nonlinearity=lasagne.nonlinearities.elu)\n",
    "dr1 = DropoutLayer(ll1, p=0.5)\n",
    "ll2 = DenseLayer(dr1, num_units=2048, nonlinearity=lasagne.nonlinearities.elu)\n",
    "dr3 = DropoutLayer(ll2, p=0.5)\n",
    "ll3 = DenseLayer(dr3, num_units=1024, nonlinearity=lasagne.nonlinearities.elu)\n",
    "dr4 = DropoutLayer(ll3, p=0.5)\n",
    "ll4 = DenseLayer(dr4, num_units=512, nonlinearity=lasagne.nonlinearities.elu)\n",
    "dr5 = DropoutLayer(ll4, p=0.5)\n",
    "ll5 = DenseLayer(dr5, num_units=256, nonlinearity=lasagne.nonlinearities.elu)\n",
    "dr6 = DropoutLayer(ll5, p=0.5)\n",
    "percentile = DenseLayer(dr6, num_units=len(set(y_train)), nonlinearity=softmax)\n",
    "\n",
    "target_y = T.vector(\"target Y integer\", dtype='int32')\n",
    "input_X = T.matrix('X')\n",
    "\n",
    "probs = lasagne.layers.get_output(percentile, input_X, deterministic = True)\n",
    "y_predicted = np.argmax(probs, axis=1)\n",
    "\n",
    "#all network weights (shared variables)\n",
    "all_weights = lasagne.layers.get_all_params(percentile)\n",
    "print(all_weights)\n",
    "\n",
    "#Mean categorical crossentropy as a loss function - similar to logistic loss but for multiclass targets\n",
    "loss = lasagne.objectives.categorical_crossentropy(probs, target_y).mean()\n",
    "l2_penalty = regularize_layer_params(percentile, l2) * 1e-1\n",
    "l1_penalty = regularize_layer_params(percentile, l1) * 1e-3\n",
    "loss += l2_penalty + l1_penalty\n",
    "\n",
    "#prediction accuracy\n",
    "accuracy = lasagne.objectives.categorical_accuracy(probs, target_y).mean()\n",
    "\n",
    "#This function computes gradient AND composes weight updates just like you did earlier\n",
    "updates_sgd = lasagne.updates.adagrad(loss, all_weights, learning_rate=0.01)\n",
    "\n",
    "#function that computes loss and updates weights\n",
    "train_fun = theano.function([input_X, target_y], [loss, accuracy], updates = updates_sgd)\n",
    "\n",
    "#function that just computes accuracy\n",
    "accuracy_fun = theano.function([input_X, target_y],accuracy)\n",
    "\n",
    "num_epochs = 30 #amount of passes through the data\n",
    "\n",
    "batch_size = 100 #number of samples processed at each function call\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(f1_train, y_train, batch_size):\n",
    "        inputs, targets = batch\n",
    "        train_err_batch, train_acc_batch = train_fun(inputs, targets.astype(np.int32))\n",
    "        train_err += train_err_batch\n",
    "        train_acc += train_acc_batch\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(f1_val, y_val, batch_size):\n",
    "        inputs, targets = batch\n",
    "        val_acc += accuracy_fun(inputs, targets.astype(np.int32))\n",
    "        val_batches += 1\n",
    "\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "\n",
    "    print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  train accuracy:\\t\\t{:.2f} %\".format(\n",
    "        train_acc / train_batches * 100))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network with road, 5 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data_basic.pkl', 'rb') as f:\n",
    "    X_train, Seg_train, y_train, X_val, Seg_val, y_val, X_test, Seg_test, y_test = pickle.load(f)\n",
    "    \n",
    "with open('features_basic.pkl', 'rb') as f:\n",
    "    f1_train, f1_val, f1_test, f2_train, f2_val, f2_test = pickle.load(f)\n",
    "    \n",
    "bins = [np.percentile(y_train, 0),\n",
    "        np.percentile(y_train, 25),\n",
    "        np.percentile(y_train, 50),\n",
    "        np.percentile(y_train, 75),\n",
    "        np.percentile(y_train, 100) + 1]\n",
    "\n",
    "y_train = np.digitize(y_train, bins) - 1\n",
    "y_val = np.digitize(y_val, bins) - 1\n",
    "y_test = np.digitize(y_test, bins) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W, b, W, b, W, b, W, b, W, b, W, b]\n",
      "Epoch 1 of 300 took 2.036s\n",
      "  training loss (in-iteration):\t\t140.387504\n",
      "  train accuracy:\t\t31.28 %\n",
      "  validation accuracy:\t\t52.80 %\n",
      "Epoch 2 of 300 took 2.016s\n",
      "  training loss (in-iteration):\t\t13.295092\n",
      "  train accuracy:\t\t55.17 %\n",
      "  validation accuracy:\t\t58.20 %\n",
      "Epoch 3 of 300 took 2.002s\n",
      "  training loss (in-iteration):\t\t12.705572\n",
      "  train accuracy:\t\t62.45 %\n",
      "  validation accuracy:\t\t60.40 %\n",
      "Epoch 4 of 300 took 2.003s\n",
      "  training loss (in-iteration):\t\t12.226186\n",
      "  train accuracy:\t\t68.86 %\n",
      "  validation accuracy:\t\t60.40 %\n",
      "Epoch 5 of 300 took 2.002s\n",
      "  training loss (in-iteration):\t\t11.880651\n",
      "  train accuracy:\t\t71.07 %\n",
      "  validation accuracy:\t\t60.20 %\n",
      "Epoch 6 of 300 took 2.014s\n",
      "  training loss (in-iteration):\t\t11.404465\n",
      "  train accuracy:\t\t79.07 %\n",
      "  validation accuracy:\t\t61.80 %\n",
      "Epoch 7 of 300 took 2.018s\n",
      "  training loss (in-iteration):\t\t11.053822\n",
      "  train accuracy:\t\t84.86 %\n",
      "  validation accuracy:\t\t65.00 %\n",
      "Epoch 8 of 300 took 1.896s\n",
      "  training loss (in-iteration):\t\t10.977491\n",
      "  train accuracy:\t\t79.59 %\n",
      "  validation accuracy:\t\t61.00 %\n",
      "Epoch 9 of 300 took 2.035s\n",
      "  training loss (in-iteration):\t\t10.554585\n",
      "  train accuracy:\t\t87.14 %\n",
      "  validation accuracy:\t\t65.00 %\n",
      "Epoch 10 of 300 took 1.963s\n",
      "  training loss (in-iteration):\t\t10.316450\n",
      "  train accuracy:\t\t90.83 %\n",
      "  validation accuracy:\t\t64.80 %\n",
      "Epoch 11 of 300 took 1.936s\n",
      "  training loss (in-iteration):\t\t10.013761\n",
      "  train accuracy:\t\t95.55 %\n",
      "  validation accuracy:\t\t63.40 %\n",
      "Epoch 12 of 300 took 1.933s\n",
      "  training loss (in-iteration):\t\t9.810423\n",
      "  train accuracy:\t\t97.24 %\n",
      "  validation accuracy:\t\t63.80 %\n",
      "Epoch 13 of 300 took 1.933s\n",
      "  training loss (in-iteration):\t\t9.722251\n",
      "  train accuracy:\t\t95.52 %\n",
      "  validation accuracy:\t\t63.00 %\n",
      "Epoch 14 of 300 took 1.922s\n",
      "  training loss (in-iteration):\t\t9.467655\n",
      "  train accuracy:\t\t99.24 %\n",
      "  validation accuracy:\t\t64.40 %\n",
      "Epoch 15 of 300 took 1.951s\n",
      "  training loss (in-iteration):\t\t9.321485\n",
      "  train accuracy:\t\t99.38 %\n",
      "  validation accuracy:\t\t66.20 %\n",
      "Epoch 16 of 300 took 1.924s\n",
      "  training loss (in-iteration):\t\t9.184269\n",
      "  train accuracy:\t\t99.72 %\n",
      "  validation accuracy:\t\t65.60 %\n",
      "Epoch 17 of 300 took 1.955s\n",
      "  training loss (in-iteration):\t\t9.060074\n",
      "  train accuracy:\t\t99.86 %\n",
      "  validation accuracy:\t\t65.60 %\n",
      "Epoch 18 of 300 took 2.053s\n",
      "  training loss (in-iteration):\t\t8.943007\n",
      "  train accuracy:\t\t99.93 %\n",
      "  validation accuracy:\t\t64.40 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-c68afadbdafd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mtrain_err_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mtrain_err\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain_err_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain_acc_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_layer = InputLayer((None, f1_train[0].shape[0]))\n",
    "ll1 = DenseLayer(input_layer, num_units=2048, nonlinearity=lasagne.nonlinearities.elu)\n",
    "dr1 = DropoutLayer(ll1, p=0.5)\n",
    "ll2 = DenseLayer(dr1, num_units=2048, nonlinearity=lasagne.nonlinearities.elu)\n",
    "dr3 = DropoutLayer(ll2, p=0.5)\n",
    "ll3 = DenseLayer(dr3, num_units=1024, nonlinearity=lasagne.nonlinearities.elu)\n",
    "dr4 = DropoutLayer(ll3, p=0.5)\n",
    "ll4 = DenseLayer(dr4, num_units=512, nonlinearity=lasagne.nonlinearities.elu)\n",
    "dr5 = DropoutLayer(ll4, p=0.5)\n",
    "ll5 = DenseLayer(dr5, num_units=256, nonlinearity=lasagne.nonlinearities.elu)\n",
    "dr6 = DropoutLayer(ll5, p=0.5)\n",
    "percentile = DenseLayer(dr6, num_units=len(set(y_train)), nonlinearity=softmax)\n",
    "\n",
    "target_y = T.vector(\"target Y integer\", dtype='int32')\n",
    "input_X = T.matrix('X')\n",
    "\n",
    "probs = lasagne.layers.get_output(percentile, input_X, deterministic = True)\n",
    "y_predicted = np.argmax(probs, axis=1)\n",
    "\n",
    "#all network weights (shared variables)\n",
    "all_weights = lasagne.layers.get_all_params(percentile)\n",
    "print(all_weights)\n",
    "\n",
    "#Mean categorical crossentropy as a loss function - similar to logistic loss but for multiclass targets\n",
    "loss = lasagne.objectives.categorical_crossentropy(probs, target_y).mean()\n",
    "l2_penalty = regularize_layer_params(percentile, l2) * 1e-1\n",
    "l1_penalty = regularize_layer_params(percentile, l1) * 1e-2\n",
    "loss += l2_penalty + l1_penalty\n",
    "\n",
    "#prediction accuracy\n",
    "accuracy = lasagne.objectives.categorical_accuracy(probs, target_y).mean()\n",
    "\n",
    "#This function computes gradient AND composes weight updates just like you did earlier\n",
    "updates_sgd = lasagne.updates.adagrad(loss, all_weights, learning_rate=0.005)\n",
    "\n",
    "#function that computes loss and updates weights\n",
    "train_fun = theano.function([input_X, target_y], [loss, accuracy], updates = updates_sgd)\n",
    "\n",
    "#function that just computes accuracy\n",
    "accuracy_fun = theano.function([input_X, target_y],accuracy)\n",
    "\n",
    "num_epochs = 300 #amount of passes through the data\n",
    "\n",
    "batch_size = 100 #number of samples processed at each function call\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(f1_train, y_train, batch_size):\n",
    "        inputs, targets = batch\n",
    "        train_err_batch, train_acc_batch = train_fun(inputs, targets.astype(np.int32))\n",
    "        train_err += train_err_batch\n",
    "        train_acc += train_acc_batch\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(f1_val, y_val, batch_size):\n",
    "        inputs, targets = batch\n",
    "        val_acc += accuracy_fun(inputs, targets.astype(np.int32))\n",
    "        val_batches += 1\n",
    "\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "\n",
    "    print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  train accuracy:\\t\\t{:.2f} %\".format(\n",
    "        train_acc / train_batches * 100))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network deleted road, 5 classes, stacked with segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W, b, W, b, W, b]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Error allocating 603979776 bytes of device memory (out of memory).\nApply node that caused the error: GpuDot22(GpuDimShuffle{1,0}.0, GpuElemwise{Composite{(i0 + (i0 * sgn(i1)))}}[(0, 0)].0)\nToposort index: 54\nInputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(36864, 100), (100, 4096)]\nInputs strides: [(1, 36864), (4096, 1)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[GpuElemwise{Sqr}[(0, 0)](GpuDot22.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-7a80a87eb928>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf1_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mtrain_err_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[0mtrain_err\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain_err_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain_acc_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/user/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    910\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[0;32m    913\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/user/anaconda2/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/user/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 899\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    900\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Error allocating 603979776 bytes of device memory (out of memory).\nApply node that caused the error: GpuDot22(GpuDimShuffle{1,0}.0, GpuElemwise{Composite{(i0 + (i0 * sgn(i1)))}}[(0, 0)].0)\nToposort index: 54\nInputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(36864, 100), (100, 4096)]\nInputs strides: [(1, 36864), (4096, 1)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[GpuElemwise{Sqr}[(0, 0)](GpuDot22.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "with open('data_rem_road.pkl', 'rb') as f:\n",
    "    X_train, Seg_train, y_train, X_val, Seg_val, y_val, X_test, Seg_test, y_test = pickle.load(f)\n",
    "    \n",
    "with open('features_rem_road.pkl', 'rb') as f:\n",
    "    f1_train, f1_val, f1_test, f2_train, f2_val, f2_test = pickle.load(f)\n",
    "    \n",
    "f1_train = np.hstack((np.array(f1_train), np.array(f2_train)))\n",
    "f1_val = np.hstack((np.array(f1_val), np.array(f2_val)))\n",
    "    \n",
    "bins = [np.percentile(y_train, 0),\n",
    "        np.percentile(y_train, 25),\n",
    "        np.percentile(y_train, 50),\n",
    "        np.percentile(y_train, 75),\n",
    "        np.percentile(y_train, 100) + 1]\n",
    "\n",
    "y_train = np.digitize(y_train, bins) - 1\n",
    "y_val = np.digitize(y_val, bins) - 1\n",
    "y_test = np.digitize(y_test, bins) - 1\n",
    "\n",
    "input_layer = InputLayer((None, f1_train[0].shape[0]))\n",
    "ll1 = DenseLayer(input_layer, num_units=4096)\n",
    "dr1 = DropoutLayer(ll1, p=0.5)\n",
    "ll2 = DenseLayer(dr1, num_units=4096)\n",
    "dr3 = DropoutLayer(ll2, p=0.5)\n",
    "percentile = DenseLayer(dr3, num_units=len(set(y_train)), nonlinearity=softmax)\n",
    "\n",
    "target_y = T.vector(\"target Y integer\", dtype='int32')\n",
    "input_X = T.matrix('X')\n",
    "\n",
    "probs = lasagne.layers.get_output(percentile, input_X, deterministic = True)\n",
    "y_predicted = np.argmax(probs, axis=1)\n",
    "\n",
    "#all network weights (shared variables)\n",
    "all_weights = lasagne.layers.get_all_params(percentile)\n",
    "print(all_weights)\n",
    "\n",
    "#Mean categorical crossentropy as a loss function - similar to logistic loss but for multiclass targets\n",
    "loss = lasagne.objectives.categorical_crossentropy(probs, target_y).mean()\n",
    "l2_penalty = regularize_layer_params(percentile, l2) * 1e-2\n",
    "l1_penalty = regularize_layer_params(percentile, l1) * 1e-3\n",
    "loss += l2_penalty + l1_penalty\n",
    "\n",
    "#prediction accuracy\n",
    "accuracy = lasagne.objectives.categorical_accuracy(probs, target_y).mean()\n",
    "\n",
    "#This function computes gradient AND composes weight updates just like you did earlier\n",
    "updates_sgd = lasagne.updates.adagrad(loss, all_weights, learning_rate=0.01)\n",
    "\n",
    "#function that computes loss and updates weights\n",
    "train_fun = theano.function([input_X, target_y], [loss, accuracy], updates = updates_sgd)\n",
    "\n",
    "#function that just computes accuracy\n",
    "accuracy_fun = theano.function([input_X, target_y],accuracy)\n",
    "\n",
    "num_epochs = 30 #amount of passes through the data\n",
    "\n",
    "batch_size = 100 #number of samples processed at each function call\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(f1_train, y_train, batch_size):\n",
    "        inputs, targets = batch\n",
    "        train_err_batch, train_acc_batch = train_fun(inputs, targets.astype(np.int32))\n",
    "        train_err += train_err_batch\n",
    "        train_acc += train_acc_batch\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(f1_val, y_val, batch_size):\n",
    "        inputs, targets = batch\n",
    "        val_acc += accuracy_fun(inputs, targets.astype(np.int32))\n",
    "        val_batches += 1\n",
    "\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "\n",
    "    print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  train accuracy:\\t\\t{:.2f} %\".format(\n",
    "        train_acc / train_batches * 100))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network with road, 5 classes, stacked with segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W, b, W, b, W, b]\n",
      "Epoch 1 of 30 took 4.315s\n",
      "  training loss (in-iteration):\t\t4726.092065\n",
      "  train accuracy:\t\t24.38 %\n",
      "  validation accuracy:\t\t33.00 %\n",
      "Epoch 2 of 30 took 4.367s\n",
      "  training loss (in-iteration):\t\t11.885494\n",
      "  train accuracy:\t\t30.03 %\n",
      "  validation accuracy:\t\t26.00 %\n",
      "Epoch 3 of 30 took 4.157s\n",
      "  training loss (in-iteration):\t\t5.118199\n",
      "  train accuracy:\t\t30.03 %\n",
      "  validation accuracy:\t\t25.20 %\n",
      "Epoch 4 of 30 took 4.156s\n",
      "  training loss (in-iteration):\t\t4.719048\n",
      "  train accuracy:\t\t33.24 %\n",
      "  validation accuracy:\t\t25.00 %\n",
      "Epoch 5 of 30 took 4.154s\n",
      "  training loss (in-iteration):\t\t4.602650\n",
      "  train accuracy:\t\t33.83 %\n",
      "  validation accuracy:\t\t25.40 %\n",
      "Epoch 6 of 30 took 4.158s\n",
      "  training loss (in-iteration):\t\t4.511264\n",
      "  train accuracy:\t\t34.45 %\n",
      "  validation accuracy:\t\t29.20 %\n",
      "Epoch 7 of 30 took 4.156s\n",
      "  training loss (in-iteration):\t\t4.433514\n",
      "  train accuracy:\t\t35.31 %\n",
      "  validation accuracy:\t\t31.80 %\n",
      "Epoch 8 of 30 took 4.153s\n",
      "  training loss (in-iteration):\t\t4.364174\n",
      "  train accuracy:\t\t35.90 %\n",
      "  validation accuracy:\t\t33.00 %\n",
      "Epoch 9 of 30 took 4.321s\n",
      "  training loss (in-iteration):\t\t4.301553\n",
      "  train accuracy:\t\t36.66 %\n",
      "  validation accuracy:\t\t34.60 %\n",
      "Epoch 10 of 30 took 4.163s\n",
      "  training loss (in-iteration):\t\t4.242831\n",
      "  train accuracy:\t\t38.03 %\n",
      "  validation accuracy:\t\t36.00 %\n",
      "Epoch 11 of 30 took 4.158s\n",
      "  training loss (in-iteration):\t\t4.186211\n",
      "  train accuracy:\t\t40.17 %\n",
      "  validation accuracy:\t\t37.40 %\n",
      "Epoch 12 of 30 took 4.189s\n",
      "  training loss (in-iteration):\t\t4.131390\n",
      "  train accuracy:\t\t42.07 %\n",
      "  validation accuracy:\t\t37.60 %\n",
      "Epoch 13 of 30 took 4.163s\n",
      "  training loss (in-iteration):\t\t4.075547\n",
      "  train accuracy:\t\t43.79 %\n",
      "  validation accuracy:\t\t39.00 %\n",
      "Epoch 14 of 30 took 4.183s\n",
      "  training loss (in-iteration):\t\t4.020848\n",
      "  train accuracy:\t\t45.31 %\n",
      "  validation accuracy:\t\t40.00 %\n",
      "Epoch 15 of 30 took 4.165s\n",
      "  training loss (in-iteration):\t\t3.965067\n",
      "  train accuracy:\t\t47.62 %\n",
      "  validation accuracy:\t\t42.20 %\n",
      "Epoch 16 of 30 took 4.164s\n",
      "  training loss (in-iteration):\t\t3.908799\n",
      "  train accuracy:\t\t50.52 %\n",
      "  validation accuracy:\t\t42.60 %\n",
      "Epoch 17 of 30 took 4.170s\n",
      "  training loss (in-iteration):\t\t3.857314\n",
      "  train accuracy:\t\t53.24 %\n",
      "  validation accuracy:\t\t43.60 %\n",
      "Epoch 18 of 30 took 4.167s\n",
      "  training loss (in-iteration):\t\t3.806450\n",
      "  train accuracy:\t\t55.59 %\n",
      "  validation accuracy:\t\t43.20 %\n",
      "Epoch 19 of 30 took 4.179s\n",
      "  training loss (in-iteration):\t\t3.757564\n",
      "  train accuracy:\t\t57.03 %\n",
      "  validation accuracy:\t\t43.20 %\n",
      "Epoch 20 of 30 took 4.165s\n",
      "  training loss (in-iteration):\t\t3.713492\n",
      "  train accuracy:\t\t58.41 %\n",
      "  validation accuracy:\t\t42.40 %\n",
      "Epoch 21 of 30 took 4.181s\n",
      "  training loss (in-iteration):\t\t3.673273\n",
      "  train accuracy:\t\t59.66 %\n",
      "  validation accuracy:\t\t42.20 %\n",
      "Epoch 22 of 30 took 4.169s\n",
      "  training loss (in-iteration):\t\t3.635788\n",
      "  train accuracy:\t\t60.59 %\n",
      "  validation accuracy:\t\t43.00 %\n",
      "Epoch 23 of 30 took 4.188s\n",
      "  training loss (in-iteration):\t\t3.601693\n",
      "  train accuracy:\t\t61.66 %\n",
      "  validation accuracy:\t\t40.60 %\n",
      "Epoch 24 of 30 took 4.169s\n",
      "  training loss (in-iteration):\t\t3.569888\n",
      "  train accuracy:\t\t63.17 %\n",
      "  validation accuracy:\t\t41.60 %\n",
      "Epoch 25 of 30 took 4.192s\n",
      "  training loss (in-iteration):\t\t3.539712\n",
      "  train accuracy:\t\t63.79 %\n",
      "  validation accuracy:\t\t41.00 %\n",
      "Epoch 26 of 30 took 4.172s\n",
      "  training loss (in-iteration):\t\t3.510056\n",
      "  train accuracy:\t\t64.86 %\n",
      "  validation accuracy:\t\t41.40 %\n",
      "Epoch 27 of 30 took 4.164s\n",
      "  training loss (in-iteration):\t\t3.482480\n",
      "  train accuracy:\t\t66.41 %\n",
      "  validation accuracy:\t\t40.20 %\n",
      "Epoch 28 of 30 took 4.187s\n",
      "  training loss (in-iteration):\t\t3.455721\n",
      "  train accuracy:\t\t67.69 %\n",
      "  validation accuracy:\t\t40.80 %\n",
      "Epoch 29 of 30 took 4.164s\n",
      "  training loss (in-iteration):\t\t3.428972\n",
      "  train accuracy:\t\t68.83 %\n",
      "  validation accuracy:\t\t41.20 %\n",
      "Epoch 30 of 30 took 4.173s\n",
      "  training loss (in-iteration):\t\t3.419649\n",
      "  train accuracy:\t\t68.41 %\n",
      "  validation accuracy:\t\t41.20 %\n"
     ]
    }
   ],
   "source": [
    "with open('data_basic.pkl', 'rb') as f:\n",
    "    X_train, Seg_train, y_train, X_val, Seg_val, y_val, X_test, Seg_test, y_test = pickle.load(f)\n",
    "    \n",
    "with open('features_basic.pkl', 'rb') as f:\n",
    "    f1_train, f1_val, f1_test, f2_train, f2_val, f2_test = pickle.load(f)\n",
    "    \n",
    "f1_train = np.hstack((np.array(f1_train), np.array(f2_train)))\n",
    "f1_val = np.hstack((np.array(f1_val), np.array(f2_val)))\n",
    "    \n",
    "bins = [np.percentile(y_train, 0),\n",
    "        np.percentile(y_train, 25),\n",
    "        np.percentile(y_train, 50),\n",
    "        np.percentile(y_train, 75),\n",
    "        np.percentile(y_train, 100) + 1]\n",
    "\n",
    "y_train = np.digitize(y_train, bins) - 1\n",
    "y_val = np.digitize(y_val, bins) - 1\n",
    "y_test = np.digitize(y_test, bins) - 1\n",
    "\n",
    "input_layer = InputLayer((None, f1_train[0].shape[0]))\n",
    "ll1 = DenseLayer(input_layer, num_units=4096)\n",
    "dr1 = DropoutLayer(ll1, p=0.5)\n",
    "ll2 = DenseLayer(dr1, num_units=4096)\n",
    "dr3 = DropoutLayer(ll2, p=0.5)\n",
    "percentile = DenseLayer(dr3, num_units=len(set(y_train)), nonlinearity=softmax)\n",
    "\n",
    "target_y = T.vector(\"target Y integer\", dtype='int32')\n",
    "input_X = T.matrix('X')\n",
    "\n",
    "probs = lasagne.layers.get_output(percentile, input_X, deterministic = True)\n",
    "y_predicted = np.argmax(probs, axis=1)\n",
    "\n",
    "#all network weights (shared variables)\n",
    "all_weights = lasagne.layers.get_all_params(percentile)\n",
    "print(all_weights)\n",
    "\n",
    "#Mean categorical crossentropy as a loss function - similar to logistic loss but for multiclass targets\n",
    "loss = lasagne.objectives.categorical_crossentropy(probs, target_y).mean()\n",
    "l2_penalty = regularize_layer_params(percentile, l2) * 1e-1\n",
    "l1_penalty = regularize_layer_params(percentile, l1) * 1e-2\n",
    "loss += l2_penalty + l1_penalty\n",
    "\n",
    "#prediction accuracy\n",
    "accuracy = lasagne.objectives.categorical_accuracy(probs, target_y).mean()\n",
    "\n",
    "#This function computes gradient AND composes weight updates just like you did earlier\n",
    "updates_sgd = lasagne.updates.adagrad(loss, all_weights, learning_rate=0.01)\n",
    "\n",
    "#function that computes loss and updates weights\n",
    "train_fun = theano.function([input_X, target_y], [loss, accuracy], updates = updates_sgd)\n",
    "\n",
    "#function that just computes accuracy\n",
    "accuracy_fun = theano.function([input_X, target_y],accuracy)\n",
    "\n",
    "num_epochs = 30 #amount of passes through the data\n",
    "\n",
    "batch_size = 100 #number of samples processed at each function call\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(f1_train, y_train, batch_size):\n",
    "        inputs, targets = batch\n",
    "        train_err_batch, train_acc_batch = train_fun(inputs, targets.astype(np.int32))\n",
    "        train_err += train_err_batch\n",
    "        train_acc += train_acc_batch\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(f1_val, y_val, batch_size):\n",
    "        inputs, targets = batch\n",
    "        val_acc += accuracy_fun(inputs, targets.astype(np.int32))\n",
    "        val_batches += 1\n",
    "\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "\n",
    "    print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  train accuracy:\\t\\t{:.2f} %\".format(\n",
    "        train_acc / train_batches * 100))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
